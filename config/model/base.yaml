# Managed by Hydra

ckpt_path: 
log:
  module: WandbLogger  # WandbLogger or TensorBoardLogger
  # https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html
  WandbLogger:
    project: General
    name: run_1
  # https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.tensorboard.html
  TensorBoardLogger:
    name: General
    default_hp_metric: False


# https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
trainer:
  accelerator: gpu
  devices: auto
  strategy: ddp
  num_nodes: 1
  max_epochs: 496
  num_sanity_val_steps: 2O
  check_val_every_n_epoch: 2


# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html
checkpoint_monitor:
  monitor: null
  mode: max
  save_last: False
  save_top_k: -1
  every_n_epochs: 1


# https://pytorch-lightning.readthedocs.io/en/stable/common/optimization.html
optimizer:
    name: Adam # Adam, AdamW or SGD
    lr: 0.001


lr_decay:
  decay_start_epoch: 200
  decay_stop_epoch: 512


inference:
  TEST_NMS_THRESH: 1 #Not doing nms will significantly lower the score of pointgroup. Hence, the TEST_NMS_THRESH of pointgroup is set independently in pointgrou.yaml
  split: test
  evaluate: True
  save_predictions: False
  show_visualization: True
  output_dir: prediction
