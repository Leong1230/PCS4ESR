# Managed by Hydra

# ckpt_path: /localhome/zla247/projects/data/output/Scannet/AutoDecoder/stage-1_AutoDecoder_overfit-True_intake-10_0.5_latent-64_norm-initial_inner-steps-300_lr-0.002-0.001-0.005_reg-True_reg-lambda-0.0001_L1-blocks-[1, 2, 3]-[1, 2, 3]_run_1/training/epoch=149.ckpt
ckpt_path: 

logger:
  # https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html
  _target_: pytorch_lightning.loggers.WandbLogger
  project: HybridPC
  name: ${experiment_name}

# https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
trainer:
  accelerator: gpu #cpu or gpu
  devices: auto
  strategy: ddp_find_unused_parameters_true
  num_nodes: 1
  max_epochs: 800
  num_sanity_val_steps: 10
  check_val_every_n_epoch: 10
  profiler: simple

# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html
checkpoint_monitor:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  save_top_k: -1
  every_n_epochs: 500                 
  filename: "{epoch}"
  dirpath: ${exp_output_root_path}/training


lr_decay:
  decay_start_epoch: 250


inference:
  term: UDF # UDF or Seg
  split: val
  evaluate: True
  save_predictions: False
  visualization: False
  show_visualizaitons: True