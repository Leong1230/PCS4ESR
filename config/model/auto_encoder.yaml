
# Managed by Hydra

defaults:
  - base


stage1_ckpt_path: '/localhome/zla247/projects/data/output/Scannet/AutoEncoder/Decoder-selecting_stage-1_voxel-0.5_overfit-True_intake-2_udf-queries-0.1-2_decoder-ConvONet_local-coords-True_normalize-encoding-True_inverse_distance-8-blocks-5_latent-64-64-64_lr-0.002_run_1/training/epoch=99.ckpt'


# stage1_ckpt_path: None

training_stage: 2
recompute_udf: False

trainer:
  max_epochs: 700

optimizer:
    target_: torch.optim.Adam
    lr: 0.002
    decreased_by: 10

loss:
  norm_initialization: True # initialize latent code by norm distirbution
  loss_type: L1 # L1 or L2
  use_reg: True # whether to use regularization
  code_reg_lambda: 1e-4 # regularization lambda

lr_decay:
  decay_start_epoch: 1000

network:
  module: AutoEncoder

  # m: 16 # 16 or 32 (U-Net hidden dimension)

  use_color: True
  use_normal: False
  use_xyz: False

  positional_encoding: Fourier # Triplane
  latent_dim: 64 #


  prepare_epochs: 10

  encoder:
    design: local-pointnet-unet
    local_pointnet: True
    down_sampler: None # None, MaxPool, Conv
    pn_hidden_dim: 64
    pn_n_blocks: 6
    use_unet: True
    voxel_size_out: 0.5
    feature_in: voxel_features
    unet_blocks: [1, 2, 3, 4, 5]
    unet_block_reps: 2

  udf_decoder:
    decoder_type: ConvONet # ConvONet or CrossAttention or Concatenate
    interpolation_mode: inverse_distance # inverse_distance or max or trilinear
    local_coords: True
    normalize_encoding: True
    k_neighbors: 8 # 1 for no interpolation

    input_dim: 3
    hidden_dim: 64
    num_hidden_layers_before_skip: 5
    num_hidden_layers_after_skip: 1

  seg_decoder:
    decoder_type: ConvONet
    interpolation_mode: inverse_distance # inverse_distance or max or trilinear
    local_coords: True
    normalize_encoding: True
    k_neighbors: 8 # 1 for no interpolation

    input_dim: 3
    feature_dim: 64
    hidden_dim: 128
    num_hidden_layers_before_skip: 5
    num_hidden_layers_after_skip: 1


dense_generator:
  num_steps: 10
  threshold: 0.1
  num_points: 900000
  filter_val: 0.005
  prepare_epochs: 900
  type: multiple_voxels # multiple_voxels or voxel or scene

inference:
  term: UDF # UDF or Seg
  split: val
  evaluate: True
  save_predictions: True
  visualization: True
  show_visualizations: True
  visualize_given_voxels: False
  visualize_ids: [406, 405, 366, 365, 403, 402, 410, 363, 409, 362]