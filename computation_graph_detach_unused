digraph {
	graph [size="395.55,395.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139954293956256 [label="
 ()" fillcolor=darkolivegreen1]
	139954398104784 [label=AddBackward0]
	139954398102000 -> 139954398104784
	139954398102000 [label=AddBackward0]
	139954427586976 -> 139954398102000
	139954427586976 [label=AddBackward0]
	139954427586448 -> 139954427586976
	139954427586448 [label=MulBackward0]
	139954427586880 -> 139954427586448
	139954427586880 [label=L1LossBackward0]
	139954427587120 -> 139954427586880
	139954427587120 [label=ClampBackward1]
	139954427585248 -> 139954427587120
	139954427585248 [label=SqueezeBackward1]
	139954427585488 -> 139954427585248
	139954427585488 [label=TanhBackward0]
	139954427586208 -> 139954427585488
	139954427586208 [label=AddmmBackward0]
	139954427584816 -> 139954427586208
	139954425807952 [label="udf_decoder.out.1.bias
 (1)" fillcolor=lightblue]
	139954425807952 -> 139954427584816
	139954427584816 [label=AccumulateGrad]
	139954427588176 -> 139954427586208
	139954427588176 [label=AddmmBackward0]
	139954427586736 -> 139954427588176
	139954425807792 [label="udf_decoder.out.0.bias
 (32)" fillcolor=lightblue]
	139954425807792 -> 139954427586736
	139954427586736 [label=AccumulateGrad]
	139954427587504 -> 139954427588176
	139954427587504 [label=CatBackward0]
	139954427587408 -> 139954427587504
	139954427587408 [label=LeakyReluBackward1]
	139954427587696 -> 139954427587408
	139954427587696 [label=AddmmBackward0]
	139954427574640 -> 139954427587696
	139954425807632 [label="udf_decoder.per_scale_out.0.after_skip.1.0.bias
 (32)" fillcolor=lightblue]
	139954425807632 -> 139954427574640
	139954427574640 [label=AccumulateGrad]
	139954427575456 -> 139954427587696
	139954427575456 [label=LeakyReluBackward1]
	139954427650592 -> 139954427575456
	139954427650592 [label=AddmmBackward0]
	139954427652128 -> 139954427650592
	139954425807472 [label="udf_decoder.per_scale_out.0.after_skip.0.0.bias
 (32)" fillcolor=lightblue]
	139954425807472 -> 139954427652128
	139954427652128 [label=AccumulateGrad]
	139954427650784 -> 139954427650592
	139954427650784 [label=AddBackward0]
	139954427651696 -> 139954427650784
	139954427651696 [label=LeakyReluBackward1]
	139954427650976 -> 139954427651696
	139954427650976 [label=AddmmBackward0]
	139954427652416 -> 139954427650976
	139954425807232 [label="udf_decoder.per_scale_out.0.before_skip.1.0.bias
 (32)" fillcolor=lightblue]
	139954425807232 -> 139954427652416
	139954427652416 [label=AccumulateGrad]
	139954427651744 -> 139954427650976
	139954427651744 [label=LeakyReluBackward1]
	139954427652608 -> 139954427651744
	139954427652608 [label=AddmmBackward0]
	139954427650352 -> 139954427652608
	139954425807072 [label="udf_decoder.per_scale_out.0.before_skip.0.0.bias
 (32)" fillcolor=lightblue]
	139954425807072 -> 139954427650352
	139954427650352 [label=AccumulateGrad]
	139954427652896 -> 139954427652608
	139954427652896 [label=LeakyReluBackward1]
	139954427653424 -> 139954427652896
	139954427653424 [label=AddmmBackward0]
	139954427653808 -> 139954427653424
	139954425773808 [label="udf_decoder.per_scale_out.0.in_layer.0.bias
 (32)" fillcolor=lightblue]
	139954425773808 -> 139954427653808
	139954427653808 [label=AccumulateGrad]
	139954427613488 -> 139954427653424
	139954427613488 [label=SqueezeBackward1]
	139954427616512 -> 139954427613488
	139954427616512 [label=TransposeBackward0]
	139954427617232 -> 139954427616512
	139954427617232 [label=LeakyReluBackward1]
	139954396717984 -> 139954427617232
	139954396717984 [label=CudnnBatchNormBackward0]
	139954396717456 -> 139954396717984
	139954396717456 [label=ConvolutionBackward0]
	139954396718272 -> 139954396717456
	139954396718272 [label=TransposeBackward0]
	139954396718032 -> 139954396718272
	139954396718032 [label=SumBackward1]
	139954396718080 -> 139954396718032
	139954396718080 [label=MulBackward0]
	139954396718512 -> 139954396718080
	139954396718512 [label=IndexPutBackward0]
	139954396718560 -> 139954396718512
	139954396718560 [label=CatBackward0]
	139954396718800 -> 139954396718560
	139954396718800 [label=IndexBackward0]
	139954396718896 -> 139954396718800
	139954396718896 [label=CatBackward0]
	139954396719040 -> 139954396718896
	139954396719040 [label=IndexBackward0]
	139954396719136 -> 139954396719040
	139954396719136 [label=ReluBackward0]
	139954396719232 -> 139954396719136
	139954396719232 [label=AddmmBackward0]
	139954396719328 -> 139954396719232
	139954425709488 [label="udf_decoder.per_scale_in.0.0.bias
 (8)" fillcolor=lightblue]
	139954425709488 -> 139954396719328
	139954396719328 [label=AccumulateGrad]
	139954396719280 -> 139954396719232
	139954396719280 [label=ReluBackward0]
	139954396719424 -> 139954396719280
	139954396719424 [label=NativeBatchNormBackward0]
	139954396719616 -> 139954396719424
	139954396719616 [label=AddBackward0]
	139954293956672 -> 139954396719616
	139954293956672 [label=MinkowskiConvolutionFunctionBackward]
	139954396719904 -> 139954293956672
	139954396719904 [label=ReluBackward0]
	139954396720048 -> 139954396719904
	139954396720048 [label=NativeBatchNormBackward0]
	139954293952080 -> 139954396720048
	139954293952080 [label=MinkowskiConvolutionFunctionBackward]
	139954396720288 -> 139954293952080
	139954396720288 [label=ReluBackward0]
	139954396720432 -> 139954396720288
	139954396720432 [label=NativeBatchNormBackward0]
	139954396719808 -> 139954396720432
	139954396719808 [label=AddBackward0]
	139954293951840 -> 139954396719808
	139954293951840 [label=MinkowskiConvolutionFunctionBackward]
	139954396720768 -> 139954293951840
	139954396720768 [label=ReluBackward0]
	139954396720912 -> 139954396720768
	139954396720912 [label=NativeBatchNormBackward0]
	139954293951600 -> 139954396720912
	139954293951600 [label=MinkowskiConvolutionFunctionBackward]
	139954396721104 -> 139954293951600
	139954396721104 [label=ReluBackward0]
	139954294038736 -> 139954396721104
	139954294038736 [label=NativeBatchNormBackward0]
	139954294038832 -> 139954294038736
	139954294038832 [label=CatBackward0]
	139954294039024 -> 139954294038832
	139954294039024 [label=AddBackward0]
	139954395440128 -> 139954294039024
	139954395440128 [label=MinkowskiConvolutionFunctionBackward]
	139954294039216 -> 139954395440128
	139954294039216 [label=ReluBackward0]
	139954294039360 -> 139954294039216
	139954294039360 [label=NativeBatchNormBackward0]
	139954395439888 -> 139954294039360
	139954395439888 [label=MinkowskiConvolutionFunctionBackward]
	139954294039600 -> 139954395439888
	139954294039600 [label=ReluBackward0]
	139954294039744 -> 139954294039600
	139954294039744 [label=NativeBatchNormBackward0]
	139954294039120 -> 139954294039744
	139954294039120 [label=AddBackward0]
	139954395439648 -> 139954294039120
	139954395439648 [label=MinkowskiConvolutionFunctionBackward]
	139954294040032 -> 139954395439648
	139954294040032 [label=ReluBackward0]
	139954294040176 -> 139954294040032
	139954294040176 [label=NativeBatchNormBackward0]
	139954395439408 -> 139954294040176
	139954395439408 [label=MinkowskiConvolutionFunctionBackward]
	139954294040416 -> 139954395439408
	139954294040416 [label=ReluBackward0]
	139954294040560 -> 139954294040416
	139954294040560 [label=NativeBatchNormBackward0]
	139954395439168 -> 139954294040560
	139954395439168 [label=MinkowskiConvolutionFunctionBackward]
	139954294040800 -> 139954395439168
	139954294040800 [label=DivBackward0]
	139954294040944 -> 139954294040800
	139954294040944 [label=ScatterAddBackward0]
	139954294041040 -> 139954294040944
	139954294041040 [label=AddmmBackward0]
	139954294041136 -> 139954294041040
	139954427026704 [label="encoder.local_pointnet.fc_c.bias
 (8)" fillcolor=lightblue]
	139954427026704 -> 139954294041136
	139954294041136 [label=AccumulateGrad]
	139954294041088 -> 139954294041040
	139954294041088 [label=AddBackward0]
	139954294041232 -> 139954294041088
	139954294041232 [label=MmBackward0]
	139954294041472 -> 139954294041232
	139954294041472 [label=AddmmBackward0]
	139954294041616 -> 139954294041472
	139954427024384 [label="encoder.local_pointnet.fc_pos.bias
 (16)" fillcolor=lightblue]
	139954427024384 -> 139954294041616
	139954294041616 [label=AccumulateGrad]
	139954294041568 -> 139954294041472
	139954294041568 [label=TBackward0]
	139954294041664 -> 139954294041568
	139954427024224 [label="encoder.local_pointnet.fc_pos.weight
 (16, 6)" fillcolor=lightblue]
	139954427024224 -> 139954294041664
	139954294041664 [label=AccumulateGrad]
	139954294041424 -> 139954294041232
	139954294041424 [label=TBackward0]
	139954294041856 -> 139954294041424
	139954427025984 [label="encoder.local_pointnet.blocks.0.shortcut.weight
 (8, 16)" fillcolor=lightblue]
	139954427025984 -> 139954294041856
	139954294041856 [label=AccumulateGrad]
	139954294041280 -> 139954294041088
	139954294041280 [label=AddmmBackward0]
	139954294041760 -> 139954294041280
	139954427025824 [label="encoder.local_pointnet.blocks.0.fc_1.bias
 (8)" fillcolor=lightblue]
	139954427025824 -> 139954294041760
	139954294041760 [label=AccumulateGrad]
	139954294041712 -> 139954294041280
	139954294041712 [label=ReluBackward0]
	139954294041520 -> 139954294041712
	139954294041520 [label=AddmmBackward0]
	139954294042048 -> 139954294041520
	139954427025664 [label="encoder.local_pointnet.blocks.0.fc_0.bias
 (8)" fillcolor=lightblue]
	139954427025664 -> 139954294042048
	139954294042048 [label=AccumulateGrad]
	139954294042000 -> 139954294041520
	139954294042000 [label=ReluBackward0]
	139954294041472 -> 139954294042000
	139954294041952 -> 139954294041520
	139954294041952 [label=TBackward0]
	139954294042240 -> 139954294041952
	139954427025504 [label="encoder.local_pointnet.blocks.0.fc_0.weight
 (8, 16)" fillcolor=lightblue]
	139954427025504 -> 139954294042240
	139954294042240 [label=AccumulateGrad]
	139954294041376 -> 139954294041280
	139954294041376 [label=TBackward0]
	139954294042192 -> 139954294041376
	139954427025744 [label="encoder.local_pointnet.blocks.0.fc_1.weight
 (8, 8)" fillcolor=lightblue]
	139954427025744 -> 139954294042192
	139954294042192 [label=AccumulateGrad]
	139954294040848 -> 139954294041040
	139954294040848 [label=TBackward0]
	139954294042096 -> 139954294040848
	139954427026624 [label="encoder.local_pointnet.fc_c.weight
 (8, 8)" fillcolor=lightblue]
	139954427026624 -> 139954294042096
	139954294042096 [label=AccumulateGrad]
	139954294040752 -> 139954395439168
	139954427373184 [label="encoder.unet.0.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954427373184 -> 139954294040752
	139954294040752 [label=AccumulateGrad]
	139954294040656 -> 139954294040560
	139954427374544 [label="encoder.unet.1.blocks.block0.conv_branch.0.bn.weight
 (8)" fillcolor=lightblue]
	139954427374544 -> 139954294040656
	139954294040656 [label=AccumulateGrad]
	139954294040608 -> 139954294040560
	139954427374624 [label="encoder.unet.1.blocks.block0.conv_branch.0.bn.bias
 (8)" fillcolor=lightblue]
	139954427374624 -> 139954294040608
	139954294040608 [label=AccumulateGrad]
	139954294040368 -> 139954395439408
	139954427305312 [label="encoder.unet.1.blocks.block0.conv_branch.2.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954427305312 -> 139954294040368
	139954294040368 [label=AccumulateGrad]
	139954294040272 -> 139954294040176
	139954427304672 [label="encoder.unet.1.blocks.block0.conv_branch.3.bn.weight
 (8)" fillcolor=lightblue]
	139954427304672 -> 139954294040272
	139954294040272 [label=AccumulateGrad]
	139954294040224 -> 139954294040176
	139954427304112 [label="encoder.unet.1.blocks.block0.conv_branch.3.bn.bias
 (8)" fillcolor=lightblue]
	139954427304112 -> 139954294040224
	139954294040224 [label=AccumulateGrad]
	139954294039888 -> 139954395439648
	139954427296320 [label="encoder.unet.1.blocks.block0.conv_branch.5.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954427296320 -> 139954294039888
	139954294039888 [label=AccumulateGrad]
	139954395439168 -> 139954294039120
	139954294039840 -> 139954294039744
	139954427296160 [label="encoder.unet.1.blocks.block1.conv_branch.0.bn.weight
 (8)" fillcolor=lightblue]
	139954427296160 -> 139954294039840
	139954294039840 [label=AccumulateGrad]
	139954294039792 -> 139954294039744
	139954427296000 [label="encoder.unet.1.blocks.block1.conv_branch.0.bn.bias
 (8)" fillcolor=lightblue]
	139954427296000 -> 139954294039792
	139954294039792 [label=AccumulateGrad]
	139954294039552 -> 139954395439888
	139954427296080 [label="encoder.unet.1.blocks.block1.conv_branch.2.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954427296080 -> 139954294039552
	139954294039552 [label=AccumulateGrad]
	139954294039456 -> 139954294039360
	139954427295520 [label="encoder.unet.1.blocks.block1.conv_branch.3.bn.weight
 (8)" fillcolor=lightblue]
	139954427295520 -> 139954294039456
	139954294039456 [label=AccumulateGrad]
	139954294039408 -> 139954294039360
	139954427295200 [label="encoder.unet.1.blocks.block1.conv_branch.3.bn.bias
 (8)" fillcolor=lightblue]
	139954427295200 -> 139954294039408
	139954294039408 [label=AccumulateGrad]
	139954294039168 -> 139954395440128
	139954427295680 [label="encoder.unet.1.blocks.block1.conv_branch.5.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954427295680 -> 139954294039168
	139954294039168 [label=AccumulateGrad]
	139954294039120 -> 139954294039024
	139954293951360 -> 139954294038832
	139954293951360 [label=MinkowskiConvolutionTransposeFunctionBackward]
	139954294039504 -> 139954293951360
	139954294039504 [label=ReluBackward0]
	139954294039984 -> 139954294039504
	139954294039984 [label=NativeBatchNormBackward0]
	139954294039696 -> 139954294039984
	139954294039696 [label=AddBackward0]
	139954293951120 -> 139954294039696
	139954293951120 [label=MinkowskiConvolutionFunctionBackward]
	139954294040464 -> 139954293951120
	139954294040464 [label=ReluBackward0]
	139954294040992 -> 139954294040464
	139954294040992 [label=NativeBatchNormBackward0]
	139954293950880 -> 139954294040992
	139954293950880 [label=MinkowskiConvolutionFunctionBackward]
	139954294041328 -> 139954293950880
	139954294041328 [label=ReluBackward0]
	139954294042384 -> 139954294041328
	139954294042384 [label=NativeBatchNormBackward0]
	139954294040128 -> 139954294042384
	139954294040128 [label=AddBackward0]
	139954293950640 -> 139954294040128
	139954293950640 [label=MinkowskiConvolutionFunctionBackward]
	139954294063264 -> 139954293950640
	139954294063264 [label=ReluBackward0]
	139954294063408 -> 139954294063264
	139954294063408 [label=NativeBatchNormBackward0]
	139954293950400 -> 139954294063408
	139954293950400 [label=MinkowskiConvolutionFunctionBackward]
	139954294063648 -> 139954293950400
	139954294063648 [label=ReluBackward0]
	139954294063792 -> 139954294063648
	139954294063792 [label=NativeBatchNormBackward0]
	139954294063888 -> 139954294063792
	139954294063888 [label=CatBackward0]
	139954294064080 -> 139954294063888
	139954294064080 [label=AddBackward0]
	139954395441328 -> 139954294064080
	139954395441328 [label=MinkowskiConvolutionFunctionBackward]
	139954294064272 -> 139954395441328
	139954294064272 [label=ReluBackward0]
	139954294064416 -> 139954294064272
	139954294064416 [label=NativeBatchNormBackward0]
	139954395441088 -> 139954294064416
	139954395441088 [label=MinkowskiConvolutionFunctionBackward]
	139954294064656 -> 139954395441088
	139954294064656 [label=ReluBackward0]
	139954294064800 -> 139954294064656
	139954294064800 [label=NativeBatchNormBackward0]
	139954294064176 -> 139954294064800
	139954294064176 [label=AddBackward0]
	139954395440848 -> 139954294064176
	139954395440848 [label=MinkowskiConvolutionFunctionBackward]
	139954294065088 -> 139954395440848
	139954294065088 [label=ReluBackward0]
	139954294065232 -> 139954294065088
	139954294065232 [label=NativeBatchNormBackward0]
	139954395440608 -> 139954294065232
	139954395440608 [label=MinkowskiConvolutionFunctionBackward]
	139954294065472 -> 139954395440608
	139954294065472 [label=ReluBackward0]
	139954294065616 -> 139954294065472
	139954294065616 [label=NativeBatchNormBackward0]
	139954395440368 -> 139954294065616
	139954395440368 [label=MinkowskiConvolutionFunctionBackward]
	139954294065856 -> 139954395440368
	139954294065856 [label=ReluBackward0]
	139954294066000 -> 139954294065856
	139954294066000 [label=NativeBatchNormBackward0]
	139954294039024 -> 139954294066000
	139954294066096 -> 139954294066000
	139954427294640 [label="encoder.unet.1.conv.0.bn.weight
 (8)" fillcolor=lightblue]
	139954427294640 -> 139954294066096
	139954294066096 [label=AccumulateGrad]
	139954294066048 -> 139954294066000
	139954427294560 [label="encoder.unet.1.conv.0.bn.bias
 (8)" fillcolor=lightblue]
	139954427294560 -> 139954294066048
	139954294066048 [label=AccumulateGrad]
	139954294065808 -> 139954395440368
	139954427294480 [label="encoder.unet.1.conv.2.kernel
 (8, 8, 16)" fillcolor=lightblue]
	139954427294480 -> 139954294065808
	139954294065808 [label=AccumulateGrad]
	139954294065712 -> 139954294065616
	139954427293760 [label="encoder.unet.1.u.blocks.block0.conv_branch.0.bn.weight
 (16)" fillcolor=lightblue]
	139954427293760 -> 139954294065712
	139954294065712 [label=AccumulateGrad]
	139954294065664 -> 139954294065616
	139954427293840 [label="encoder.unet.1.u.blocks.block0.conv_branch.0.bn.bias
 (16)" fillcolor=lightblue]
	139954427293840 -> 139954294065664
	139954294065664 [label=AccumulateGrad]
	139954294065424 -> 139954395440608
	139954427272944 [label="encoder.unet.1.u.blocks.block0.conv_branch.2.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954427272944 -> 139954294065424
	139954294065424 [label=AccumulateGrad]
	139954294065328 -> 139954294065232
	139954427272544 [label="encoder.unet.1.u.blocks.block0.conv_branch.3.bn.weight
 (16)" fillcolor=lightblue]
	139954427272544 -> 139954294065328
	139954294065328 [label=AccumulateGrad]
	139954294065280 -> 139954294065232
	139954427272784 [label="encoder.unet.1.u.blocks.block0.conv_branch.3.bn.bias
 (16)" fillcolor=lightblue]
	139954427272784 -> 139954294065280
	139954294065280 [label=AccumulateGrad]
	139954294064944 -> 139954395440848
	139954427272704 [label="encoder.unet.1.u.blocks.block0.conv_branch.5.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954427272704 -> 139954294064944
	139954294064944 [label=AccumulateGrad]
	139954395440368 -> 139954294064176
	139954294064896 -> 139954294064800
	139954427272144 [label="encoder.unet.1.u.blocks.block1.conv_branch.0.bn.weight
 (16)" fillcolor=lightblue]
	139954427272144 -> 139954294064896
	139954294064896 [label=AccumulateGrad]
	139954294064848 -> 139954294064800
	139954427271744 [label="encoder.unet.1.u.blocks.block1.conv_branch.0.bn.bias
 (16)" fillcolor=lightblue]
	139954427271744 -> 139954294064848
	139954294064848 [label=AccumulateGrad]
	139954294064608 -> 139954395441088
	139954427272464 [label="encoder.unet.1.u.blocks.block1.conv_branch.2.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954427272464 -> 139954294064608
	139954294064608 [label=AccumulateGrad]
	139954294064512 -> 139954294064416
	139954427271264 [label="encoder.unet.1.u.blocks.block1.conv_branch.3.bn.weight
 (16)" fillcolor=lightblue]
	139954427271264 -> 139954294064512
	139954294064512 [label=AccumulateGrad]
	139954294064464 -> 139954294064416
	139954427271504 [label="encoder.unet.1.u.blocks.block1.conv_branch.3.bn.bias
 (16)" fillcolor=lightblue]
	139954427271504 -> 139954294064464
	139954294064464 [label=AccumulateGrad]
	139954294064224 -> 139954395441328
	139954427271424 [label="encoder.unet.1.u.blocks.block1.conv_branch.5.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954427271424 -> 139954294064224
	139954294064224 [label=AccumulateGrad]
	139954294064176 -> 139954294064080
	139954293950160 -> 139954294063888
	139954293950160 [label=MinkowskiConvolutionTransposeFunctionBackward]
	139954294064560 -> 139954293950160
	139954294064560 [label=ReluBackward0]
	139954294065040 -> 139954294064560
	139954294065040 [label=NativeBatchNormBackward0]
	139954294064752 -> 139954294065040
	139954294064752 [label=AddBackward0]
	139954293949920 -> 139954294064752
	139954293949920 [label=MinkowskiConvolutionFunctionBackward]
	139954294065520 -> 139954293949920
	139954294065520 [label=ReluBackward0]
	139954294065904 -> 139954294065520
	139954294065904 [label=NativeBatchNormBackward0]
	139954293949680 -> 139954294065904
	139954293949680 [label=MinkowskiConvolutionFunctionBackward]
	139954294066336 -> 139954293949680
	139954294066336 [label=ReluBackward0]
	139954294066480 -> 139954294066336
	139954294066480 [label=NativeBatchNormBackward0]
	139954294065184 -> 139954294066480
	139954294065184 [label=AddBackward0]
	139954293949440 -> 139954294065184
	139954293949440 [label=MinkowskiConvolutionFunctionBackward]
	139954294066816 -> 139954293949440
	139954294066816 [label=ReluBackward0]
	139954294066960 -> 139954294066816
	139954294066960 [label=NativeBatchNormBackward0]
	139954293949200 -> 139954294066960
	139954293949200 [label=MinkowskiConvolutionFunctionBackward]
	139954294067152 -> 139954293949200
	139954294067152 [label=ReluBackward0]
	139954294079696 -> 139954294067152
	139954294079696 [label=NativeBatchNormBackward0]
	139954294079792 -> 139954294079696
	139954294079792 [label=CatBackward0]
	139954294079984 -> 139954294079792
	139954294079984 [label=AddBackward0]
	139954395442528 -> 139954294079984
	139954395442528 [label=MinkowskiConvolutionFunctionBackward]
	139954294080176 -> 139954395442528
	139954294080176 [label=ReluBackward0]
	139954294080272 -> 139954294080176
	139954294080272 [label=NativeBatchNormBackward0]
	139954395442288 -> 139954294080272
	139954395442288 [label=MinkowskiConvolutionFunctionBackward]
	139954294080608 -> 139954395442288
	139954294080608 [label=ReluBackward0]
	139954294080752 -> 139954294080608
	139954294080752 [label=NativeBatchNormBackward0]
	139954294080080 -> 139954294080752
	139954294080080 [label=AddBackward0]
	139954395442048 -> 139954294080080
	139954395442048 [label=MinkowskiConvolutionFunctionBackward]
	139954294081040 -> 139954395442048
	139954294081040 [label=ReluBackward0]
	139954294081184 -> 139954294081040
	139954294081184 [label=NativeBatchNormBackward0]
	139954395441808 -> 139954294081184
	139954395441808 [label=MinkowskiConvolutionFunctionBackward]
	139954294081424 -> 139954395441808
	139954294081424 [label=ReluBackward0]
	139954294081568 -> 139954294081424
	139954294081568 [label=NativeBatchNormBackward0]
	139954395441568 -> 139954294081568
	139954395441568 [label=MinkowskiConvolutionFunctionBackward]
	139954294081808 -> 139954395441568
	139954294081808 [label=ReluBackward0]
	139954294081952 -> 139954294081808
	139954294081952 [label=NativeBatchNormBackward0]
	139954294064080 -> 139954294081952
	139954294082048 -> 139954294081952
	139954427270304 [label="encoder.unet.1.u.conv.0.bn.weight
 (16)" fillcolor=lightblue]
	139954427270304 -> 139954294082048
	139954294082048 [label=AccumulateGrad]
	139954294082000 -> 139954294081952
	139954427270544 [label="encoder.unet.1.u.conv.0.bn.bias
 (16)" fillcolor=lightblue]
	139954427270544 -> 139954294082000
	139954294082000 [label=AccumulateGrad]
	139954294081760 -> 139954395441568
	139954427270144 [label="encoder.unet.1.u.conv.2.kernel
 (8, 16, 24)" fillcolor=lightblue]
	139954427270144 -> 139954294081760
	139954294081760 [label=AccumulateGrad]
	139954294081664 -> 139954294081568
	139954427270064 [label="encoder.unet.1.u.u.blocks.block0.conv_branch.0.bn.weight
 (24)" fillcolor=lightblue]
	139954427270064 -> 139954294081664
	139954294081664 [label=AccumulateGrad]
	139954294081616 -> 139954294081568
	139954427269904 [label="encoder.unet.1.u.u.blocks.block0.conv_branch.0.bn.bias
 (24)" fillcolor=lightblue]
	139954427269904 -> 139954294081616
	139954294081616 [label=AccumulateGrad]
	139954294081376 -> 139954395441808
	139954427270224 [label="encoder.unet.1.u.u.blocks.block0.conv_branch.2.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954427270224 -> 139954294081376
	139954294081376 [label=AccumulateGrad]
	139954294081280 -> 139954294081184
	139954427269424 [label="encoder.unet.1.u.u.blocks.block0.conv_branch.3.bn.weight
 (24)" fillcolor=lightblue]
	139954427269424 -> 139954294081280
	139954294081280 [label=AccumulateGrad]
	139954294081232 -> 139954294081184
	139954427269264 [label="encoder.unet.1.u.u.blocks.block0.conv_branch.3.bn.bias
 (24)" fillcolor=lightblue]
	139954427269264 -> 139954294081232
	139954294081232 [label=AccumulateGrad]
	139954294080896 -> 139954395442048
	139954427711296 [label="encoder.unet.1.u.u.blocks.block0.conv_branch.5.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954427711296 -> 139954294080896
	139954294080896 [label=AccumulateGrad]
	139954395441568 -> 139954294080080
	139954294080848 -> 139954294080752
	139954427710736 [label="encoder.unet.1.u.u.blocks.block1.conv_branch.0.bn.weight
 (24)" fillcolor=lightblue]
	139954427710736 -> 139954294080848
	139954294080848 [label=AccumulateGrad]
	139954294080800 -> 139954294080752
	139954427710976 [label="encoder.unet.1.u.u.blocks.block1.conv_branch.0.bn.bias
 (24)" fillcolor=lightblue]
	139954427710976 -> 139954294080800
	139954294080800 [label=AccumulateGrad]
	139954294080560 -> 139954395442288
	139954427711056 [label="encoder.unet.1.u.u.blocks.block1.conv_branch.2.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954427711056 -> 139954294080560
	139954294080560 [label=AccumulateGrad]
	139954294080464 -> 139954294080272
	139954427710496 [label="encoder.unet.1.u.u.blocks.block1.conv_branch.3.bn.weight
 (24)" fillcolor=lightblue]
	139954427710496 -> 139954294080464
	139954294080464 [label=AccumulateGrad]
	139954294080416 -> 139954294080272
	139954427710176 [label="encoder.unet.1.u.u.blocks.block1.conv_branch.3.bn.bias
 (24)" fillcolor=lightblue]
	139954427710176 -> 139954294080416
	139954294080416 [label=AccumulateGrad]
	139954294080128 -> 139954395442528
	139954427710656 [label="encoder.unet.1.u.u.blocks.block1.conv_branch.5.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954427710656 -> 139954294080128
	139954294080128 [label=AccumulateGrad]
	139954294080080 -> 139954294079984
	139954293948960 -> 139954294079792
	139954293948960 [label=MinkowskiConvolutionTransposeFunctionBackward]
	139954294080512 -> 139954293948960
	139954294080512 [label=ReluBackward0]
	139954294080992 -> 139954294080512
	139954294080992 [label=NativeBatchNormBackward0]
	139954294080704 -> 139954294080992
	139954294080704 [label=AddBackward0]
	139954293948720 -> 139954294080704
	139954293948720 [label=MinkowskiConvolutionFunctionBackward]
	139954294081472 -> 139954293948720
	139954294081472 [label=ReluBackward0]
	139954294081856 -> 139954294081472
	139954294081856 [label=NativeBatchNormBackward0]
	139954293948480 -> 139954294081856
	139954293948480 [label=MinkowskiConvolutionFunctionBackward]
	139954294082288 -> 139954293948480
	139954294082288 [label=ReluBackward0]
	139954294082432 -> 139954294082288
	139954294082432 [label=NativeBatchNormBackward0]
	139954294081136 -> 139954294082432
	139954294081136 [label=AddBackward0]
	139954293943888 -> 139954294081136
	139954293943888 [label=MinkowskiConvolutionFunctionBackward]
	139954294082768 -> 139954293943888
	139954294082768 [label=ReluBackward0]
	139954294082912 -> 139954294082768
	139954294082912 [label=NativeBatchNormBackward0]
	139954293943648 -> 139954294082912
	139954293943648 [label=MinkowskiConvolutionFunctionBackward]
	139954294083152 -> 139954293943648
	139954294083152 [label=ReluBackward0]
	139954294083296 -> 139954294083152
	139954294083296 [label=NativeBatchNormBackward0]
	139954294083392 -> 139954294083296
	139954294083392 [label=CatBackward0]
	139954294083536 -> 139954294083392
	139954294083536 [label=AddBackward0]
	139954395452176 -> 139954294083536
	139954395452176 [label=MinkowskiConvolutionFunctionBackward]
	139954294100224 -> 139954395452176
	139954294100224 [label=ReluBackward0]
	139954294100368 -> 139954294100224
	139954294100368 [label=NativeBatchNormBackward0]
	139954395451936 -> 139954294100368
	139954395451936 [label=MinkowskiConvolutionFunctionBackward]
	139954294100608 -> 139954395451936
	139954294100608 [label=ReluBackward0]
	139954294100752 -> 139954294100608
	139954294100752 [label=NativeBatchNormBackward0]
	139954294100128 -> 139954294100752
	139954294100128 [label=AddBackward0]
	139954395451696 -> 139954294100128
	139954395451696 [label=MinkowskiConvolutionFunctionBackward]
	139954294101040 -> 139954395451696
	139954294101040 [label=ReluBackward0]
	139954294101184 -> 139954294101040
	139954294101184 [label=NativeBatchNormBackward0]
	139954395451456 -> 139954294101184
	139954395451456 [label=MinkowskiConvolutionFunctionBackward]
	139954294101424 -> 139954395451456
	139954294101424 [label=ReluBackward0]
	139954294101568 -> 139954294101424
	139954294101568 [label=NativeBatchNormBackward0]
	139954395442768 -> 139954294101568
	139954395442768 [label=MinkowskiConvolutionFunctionBackward]
	139954294101808 -> 139954395442768
	139954294101808 [label=ReluBackward0]
	139954294101952 -> 139954294101808
	139954294101952 [label=NativeBatchNormBackward0]
	139954294079984 -> 139954294101952
	139954294102048 -> 139954294101952
	139954427709616 [label="encoder.unet.1.u.u.conv.0.bn.weight
 (24)" fillcolor=lightblue]
	139954427709616 -> 139954294102048
	139954294102048 [label=AccumulateGrad]
	139954294102000 -> 139954294101952
	139954427709856 [label="encoder.unet.1.u.u.conv.0.bn.bias
 (24)" fillcolor=lightblue]
	139954427709856 -> 139954294102000
	139954294102000 [label=AccumulateGrad]
	139954294101760 -> 139954395442768
	139954427709776 [label="encoder.unet.1.u.u.conv.2.kernel
 (8, 24, 32)" fillcolor=lightblue]
	139954427709776 -> 139954294101760
	139954294101760 [label=AccumulateGrad]
	139954294101664 -> 139954294101568
	139954427707456 [label="encoder.unet.1.u.u.u.blocks.block0.conv_branch.0.bn.weight
 (32)" fillcolor=lightblue]
	139954427707456 -> 139954294101664
	139954294101664 [label=AccumulateGrad]
	139954294101616 -> 139954294101568
	139954427707616 [label="encoder.unet.1.u.u.u.blocks.block0.conv_branch.0.bn.bias
 (32)" fillcolor=lightblue]
	139954427707616 -> 139954294101616
	139954294101616 [label=AccumulateGrad]
	139954294101376 -> 139954395451456
	139954427709456 [label="encoder.unet.1.u.u.u.blocks.block0.conv_branch.2.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954427709456 -> 139954294101376
	139954294101376 [label=AccumulateGrad]
	139954294101280 -> 139954294101184
	139954427708096 [label="encoder.unet.1.u.u.u.blocks.block0.conv_branch.3.bn.weight
 (32)" fillcolor=lightblue]
	139954427708096 -> 139954294101280
	139954294101280 [label=AccumulateGrad]
	139954294101232 -> 139954294101184
	139954427708336 [label="encoder.unet.1.u.u.u.blocks.block0.conv_branch.3.bn.bias
 (32)" fillcolor=lightblue]
	139954427708336 -> 139954294101232
	139954294101232 [label=AccumulateGrad]
	139954294100896 -> 139954395451696
	139954427707936 [label="encoder.unet.1.u.u.u.blocks.block0.conv_branch.5.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954427707936 -> 139954294100896
	139954294100896 [label=AccumulateGrad]
	139954395442768 -> 139954294100128
	139954294100848 -> 139954294100752
	139954427708976 [label="encoder.unet.1.u.u.u.blocks.block1.conv_branch.0.bn.weight
 (32)" fillcolor=lightblue]
	139954427708976 -> 139954294100848
	139954294100848 [label=AccumulateGrad]
	139954294100800 -> 139954294100752
	139954427546736 [label="encoder.unet.1.u.u.u.blocks.block1.conv_branch.0.bn.bias
 (32)" fillcolor=lightblue]
	139954427546736 -> 139954294100800
	139954294100800 [label=AccumulateGrad]
	139954294100560 -> 139954395451936
	139954427374864 [label="encoder.unet.1.u.u.u.blocks.block1.conv_branch.2.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954427374864 -> 139954294100560
	139954294100560 [label=AccumulateGrad]
	139954294100464 -> 139954294100368
	139954427375504 [label="encoder.unet.1.u.u.u.blocks.block1.conv_branch.3.bn.weight
 (32)" fillcolor=lightblue]
	139954427375504 -> 139954294100464
	139954294100464 [label=AccumulateGrad]
	139954294100416 -> 139954294100368
	139954426748992 [label="encoder.unet.1.u.u.u.blocks.block1.conv_branch.3.bn.bias
 (32)" fillcolor=lightblue]
	139954426748992 -> 139954294100416
	139954294100416 [label=AccumulateGrad]
	139954294100176 -> 139954395452176
	139954426749392 [label="encoder.unet.1.u.u.u.blocks.block1.conv_branch.5.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954426749392 -> 139954294100176
	139954294100176 [label=AccumulateGrad]
	139954294100128 -> 139954294083536
	139954293943408 -> 139954294083392
	139954293943408 [label=MinkowskiConvolutionTransposeFunctionBackward]
	139954294100512 -> 139954293943408
	139954294100512 [label=ReluBackward0]
	139954294100992 -> 139954294100512
	139954294100992 [label=NativeBatchNormBackward0]
	139954294100704 -> 139954294100992
	139954294100704 [label=AddBackward0]
	139954293943168 -> 139954294100704
	139954293943168 [label=MinkowskiConvolutionFunctionBackward]
	139954294101472 -> 139954293943168
	139954294101472 [label=ReluBackward0]
	139954294101856 -> 139954294101472
	139954294101856 [label=NativeBatchNormBackward0]
	139954293942928 -> 139954294101856
	139954293942928 [label=MinkowskiConvolutionFunctionBackward]
	139954294102288 -> 139954293942928
	139954294102288 [label=ReluBackward0]
	139954294102432 -> 139954294102288
	139954294102432 [label=NativeBatchNormBackward0]
	139954294101136 -> 139954294102432
	139954294101136 [label=AddBackward0]
	139954293942688 -> 139954294101136
	139954293942688 [label=MinkowskiConvolutionFunctionBackward]
	139954294102768 -> 139954293942688
	139954294102768 [label=ReluBackward0]
	139954294102912 -> 139954294102768
	139954294102912 [label=NativeBatchNormBackward0]
	139954293942448 -> 139954294102912
	139954293942448 [label=MinkowskiConvolutionFunctionBackward]
	139954294103152 -> 139954293942448
	139954294103152 [label=ReluBackward0]
	139954294103296 -> 139954294103152
	139954294103296 [label=NativeBatchNormBackward0]
	139954294103392 -> 139954294103296
	139954294103392 [label=CatBackward0]
	139954294103584 -> 139954294103392
	139954294103584 [label=AddBackward0]
	139954395453376 -> 139954294103584
	139954395453376 [label=MinkowskiConvolutionFunctionBackward]
	139954294103776 -> 139954395453376
	139954294103776 [label=ReluBackward0]
	139954294103920 -> 139954294103776
	139954294103920 [label=NativeBatchNormBackward0]
	139954395453136 -> 139954294103920
	139954395453136 [label=MinkowskiConvolutionFunctionBackward]
	139954294120512 -> 139954395453136
	139954294120512 [label=ReluBackward0]
	139954294120752 -> 139954294120512
	139954294120752 [label=NativeBatchNormBackward0]
	139954294103680 -> 139954294120752
	139954294103680 [label=AddBackward0]
	139954395452896 -> 139954294103680
	139954395452896 [label=MinkowskiConvolutionFunctionBackward]
	139954294121040 -> 139954395452896
	139954294121040 [label=ReluBackward0]
	139954294121184 -> 139954294121040
	139954294121184 [label=NativeBatchNormBackward0]
	139954395452656 -> 139954294121184
	139954395452656 [label=MinkowskiConvolutionFunctionBackward]
	139954294121424 -> 139954395452656
	139954294121424 [label=ReluBackward0]
	139954294121568 -> 139954294121424
	139954294121568 [label=NativeBatchNormBackward0]
	139954395452416 -> 139954294121568
	139954395452416 [label=MinkowskiConvolutionFunctionBackward]
	139954294121808 -> 139954395452416
	139954294121808 [label=ReluBackward0]
	139954294121952 -> 139954294121808
	139954294121952 [label=NativeBatchNormBackward0]
	139954294083536 -> 139954294121952
	139954294122048 -> 139954294121952
	139954426749472 [label="encoder.unet.1.u.u.u.conv.0.bn.weight
 (32)" fillcolor=lightblue]
	139954426749472 -> 139954294122048
	139954294122048 [label=AccumulateGrad]
	139954294122000 -> 139954294121952
	139954426749552 [label="encoder.unet.1.u.u.u.conv.0.bn.bias
 (32)" fillcolor=lightblue]
	139954426749552 -> 139954294122000
	139954294122000 [label=AccumulateGrad]
	139954294121760 -> 139954395452416
	139954426749312 [label="encoder.unet.1.u.u.u.conv.2.kernel
 (8, 32, 40)" fillcolor=lightblue]
	139954426749312 -> 139954294121760
	139954294121760 [label=AccumulateGrad]
	139954294121664 -> 139954294121568
	139954426750352 [label="encoder.unet.1.u.u.u.u.blocks.block0.conv_branch.0.bn.weight
 (40)" fillcolor=lightblue]
	139954426750352 -> 139954294121664
	139954294121664 [label=AccumulateGrad]
	139954294121616 -> 139954294121568
	139954426750512 [label="encoder.unet.1.u.u.u.u.blocks.block0.conv_branch.0.bn.bias
 (40)" fillcolor=lightblue]
	139954426750512 -> 139954294121616
	139954294121616 [label=AccumulateGrad]
	139954294121376 -> 139954395452656
	139954426749872 [label="encoder.unet.1.u.u.u.u.blocks.block0.conv_branch.2.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426749872 -> 139954294121376
	139954294121376 [label=AccumulateGrad]
	139954294121280 -> 139954294121184
	139954426750992 [label="encoder.unet.1.u.u.u.u.blocks.block0.conv_branch.3.bn.weight
 (40)" fillcolor=lightblue]
	139954426750992 -> 139954294121280
	139954294121280 [label=AccumulateGrad]
	139954294121232 -> 139954294121184
	139954426751072 [label="encoder.unet.1.u.u.u.u.blocks.block0.conv_branch.3.bn.bias
 (40)" fillcolor=lightblue]
	139954426751072 -> 139954294121232
	139954294121232 [label=AccumulateGrad]
	139954294120896 -> 139954395452896
	139954426750832 [label="encoder.unet.1.u.u.u.u.blocks.block0.conv_branch.5.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426750832 -> 139954294120896
	139954294120896 [label=AccumulateGrad]
	139954395452416 -> 139954294103680
	139954294120848 -> 139954294120752
	139954426751712 [label="encoder.unet.1.u.u.u.u.blocks.block1.conv_branch.0.bn.weight
 (40)" fillcolor=lightblue]
	139954426751712 -> 139954294120848
	139954294120848 [label=AccumulateGrad]
	139954294120800 -> 139954294120752
	139954426751792 [label="encoder.unet.1.u.u.u.u.blocks.block1.conv_branch.0.bn.bias
 (40)" fillcolor=lightblue]
	139954426751792 -> 139954294120800
	139954294120800 [label=AccumulateGrad]
	139954294120560 -> 139954395453136
	139954426751392 [label="encoder.unet.1.u.u.u.u.blocks.block1.conv_branch.2.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426751392 -> 139954294120560
	139954294120560 [label=AccumulateGrad]
	139954294104016 -> 139954294103920
	139954426752272 [label="encoder.unet.1.u.u.u.u.blocks.block1.conv_branch.3.bn.weight
 (40)" fillcolor=lightblue]
	139954426752272 -> 139954294104016
	139954294104016 [label=AccumulateGrad]
	139954294103968 -> 139954294103920
	139954426752352 [label="encoder.unet.1.u.u.u.u.blocks.block1.conv_branch.3.bn.bias
 (40)" fillcolor=lightblue]
	139954426752352 -> 139954294103968
	139954294103968 [label=AccumulateGrad]
	139954294103728 -> 139954395453376
	139954426752112 [label="encoder.unet.1.u.u.u.u.blocks.block1.conv_branch.5.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426752112 -> 139954294103728
	139954294103728 [label=AccumulateGrad]
	139954294103680 -> 139954294103584
	139954293942208 -> 139954294103392
	139954293942208 [label=MinkowskiConvolutionTransposeFunctionBackward]
	139954294103824 -> 139954293942208
	139954294103824 [label=ReluBackward0]
	139954294103872 -> 139954294103824
	139954294103872 [label=NativeBatchNormBackward0]
	139954294120704 -> 139954294103872
	139954294120704 [label=AddBackward0]
	139954293941968 -> 139954294120704
	139954293941968 [label=MinkowskiConvolutionFunctionBackward]
	139954294121472 -> 139954293941968
	139954294121472 [label=ReluBackward0]
	139954294121856 -> 139954294121472
	139954294121856 [label=NativeBatchNormBackward0]
	139954293941728 -> 139954294121856
	139954293941728 [label=MinkowskiConvolutionFunctionBackward]
	139954294122288 -> 139954293941728
	139954294122288 [label=ReluBackward0]
	139954294122432 -> 139954294122288
	139954294122432 [label=NativeBatchNormBackward0]
	139954294121136 -> 139954294122432
	139954294121136 [label=AddBackward0]
	139954293941488 -> 139954294121136
	139954293941488 [label=MinkowskiConvolutionFunctionBackward]
	139954294122768 -> 139954293941488
	139954294122768 [label=ReluBackward0]
	139954294122912 -> 139954294122768
	139954294122912 [label=NativeBatchNormBackward0]
	139954293941248 -> 139954294122912
	139954293941248 [label=MinkowskiConvolutionFunctionBackward]
	139954294123152 -> 139954293941248
	139954294123152 [label=ReluBackward0]
	139954294123296 -> 139954294123152
	139954294123296 [label=NativeBatchNormBackward0]
	139954294123392 -> 139954294123296
	139954294123392 [label=CatBackward0]
	139954294123584 -> 139954294123392
	139954294123584 [label=AddBackward0]
	139954395454576 -> 139954294123584
	139954395454576 [label=MinkowskiConvolutionFunctionBackward]
	139954294123776 -> 139954395454576
	139954294123776 [label=ReluBackward0]
	139954294123920 -> 139954294123776
	139954294123920 [label=NativeBatchNormBackward0]
	139954395454336 -> 139954294123920
	139954395454336 [label=MinkowskiConvolutionFunctionBackward]
	139954294124160 -> 139954395454336
	139954294124160 [label=ReluBackward0]
	139954294124304 -> 139954294124160
	139954294124304 [label=NativeBatchNormBackward0]
	139954294123680 -> 139954294124304
	139954294123680 [label=AddBackward0]
	139954395454096 -> 139954294123680
	139954395454096 [label=MinkowskiConvolutionFunctionBackward]
	139954294124448 -> 139954395454096
	139954294124448 [label=ReluBackward0]
	139954294141184 -> 139954294124448
	139954294141184 [label=NativeBatchNormBackward0]
	139954395453856 -> 139954294141184
	139954395453856 [label=MinkowskiConvolutionFunctionBackward]
	139954294141424 -> 139954395453856
	139954294141424 [label=ReluBackward0]
	139954294141568 -> 139954294141424
	139954294141568 [label=NativeBatchNormBackward0]
	139954395453616 -> 139954294141568
	139954395453616 [label=MinkowskiConvolutionFunctionBackward]
	139954294141808 -> 139954395453616
	139954294141808 [label=ReluBackward0]
	139954294141952 -> 139954294141808
	139954294141952 [label=NativeBatchNormBackward0]
	139954294103584 -> 139954294141952
	139954294142048 -> 139954294141952
	139954426752832 [label="encoder.unet.1.u.u.u.u.conv.0.bn.weight
 (40)" fillcolor=lightblue]
	139954426752832 -> 139954294142048
	139954294142048 [label=AccumulateGrad]
	139954294142000 -> 139954294141952
	139954426752912 [label="encoder.unet.1.u.u.u.u.conv.0.bn.bias
 (40)" fillcolor=lightblue]
	139954426752912 -> 139954294142000
	139954294142000 [label=AccumulateGrad]
	139954294141760 -> 139954395453616
	139954426880384 [label="encoder.unet.1.u.u.u.u.conv.2.kernel
 (8, 40, 48)" fillcolor=lightblue]
	139954426880384 -> 139954294141760
	139954294141760 [label=AccumulateGrad]
	139954294141664 -> 139954294141568
	139954426880784 [label="encoder.unet.1.u.u.u.u.u.blocks.block0.conv_branch.0.bn.weight
 (48)" fillcolor=lightblue]
	139954426880784 -> 139954294141664
	139954294141664 [label=AccumulateGrad]
	139954294141616 -> 139954294141568
	139954426880944 [label="encoder.unet.1.u.u.u.u.u.blocks.block0.conv_branch.0.bn.bias
 (48)" fillcolor=lightblue]
	139954426880944 -> 139954294141616
	139954294141616 [label=AccumulateGrad]
	139954294141376 -> 139954395453856
	139954426880304 [label="encoder.unet.1.u.u.u.u.u.blocks.block0.conv_branch.2.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426880304 -> 139954294141376
	139954294141376 [label=AccumulateGrad]
	139954294141280 -> 139954294141184
	139954426881424 [label="encoder.unet.1.u.u.u.u.u.blocks.block0.conv_branch.3.bn.weight
 (48)" fillcolor=lightblue]
	139954426881424 -> 139954294141280
	139954294141280 [label=AccumulateGrad]
	139954294141232 -> 139954294141184
	139954426881504 [label="encoder.unet.1.u.u.u.u.u.blocks.block0.conv_branch.3.bn.bias
 (48)" fillcolor=lightblue]
	139954426881504 -> 139954294141232
	139954294141232 [label=AccumulateGrad]
	139954294140992 -> 139954395454096
	139954426881264 [label="encoder.unet.1.u.u.u.u.u.blocks.block0.conv_branch.5.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426881264 -> 139954294140992
	139954294140992 [label=AccumulateGrad]
	139954395453616 -> 139954294123680
	139954294124400 -> 139954294124304
	139954426882144 [label="encoder.unet.1.u.u.u.u.u.blocks.block1.conv_branch.0.bn.weight
 (48)" fillcolor=lightblue]
	139954426882144 -> 139954294124400
	139954294124400 [label=AccumulateGrad]
	139954294124352 -> 139954294124304
	139954426882224 [label="encoder.unet.1.u.u.u.u.u.blocks.block1.conv_branch.0.bn.bias
 (48)" fillcolor=lightblue]
	139954426882224 -> 139954294124352
	139954294124352 [label=AccumulateGrad]
	139954294124112 -> 139954395454336
	139954426881824 [label="encoder.unet.1.u.u.u.u.u.blocks.block1.conv_branch.2.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426881824 -> 139954294124112
	139954294124112 [label=AccumulateGrad]
	139954294124016 -> 139954294123920
	139954426882704 [label="encoder.unet.1.u.u.u.u.u.blocks.block1.conv_branch.3.bn.weight
 (48)" fillcolor=lightblue]
	139954426882704 -> 139954294124016
	139954294124016 [label=AccumulateGrad]
	139954294123968 -> 139954294123920
	139954426882784 [label="encoder.unet.1.u.u.u.u.u.blocks.block1.conv_branch.3.bn.bias
 (48)" fillcolor=lightblue]
	139954426882784 -> 139954294123968
	139954294123968 [label=AccumulateGrad]
	139954294123728 -> 139954395454576
	139954426882544 [label="encoder.unet.1.u.u.u.u.u.blocks.block1.conv_branch.5.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426882544 -> 139954294123728
	139954294123728 [label=AccumulateGrad]
	139954294123680 -> 139954294123584
	139954293941008 -> 139954294123392
	139954293941008 [label=MinkowskiConvolutionTransposeFunctionBackward]
	139954294124064 -> 139954293941008
	139954294124064 [label=ReluBackward0]
	139954294124496 -> 139954294124064
	139954294124496 [label=NativeBatchNormBackward0]
	139954294124256 -> 139954294124496
	139954294124256 [label=AddBackward0]
	139954293940768 -> 139954294124256
	139954293940768 [label=MinkowskiConvolutionFunctionBackward]
	139954294141472 -> 139954293940768
	139954294141472 [label=ReluBackward0]
	139954294141856 -> 139954294141472
	139954294141856 [label=NativeBatchNormBackward0]
	139954293940528 -> 139954294141856
	139954293940528 [label=MinkowskiConvolutionFunctionBackward]
	139954294142288 -> 139954293940528
	139954294142288 [label=ReluBackward0]
	139954294142432 -> 139954294142288
	139954294142432 [label=NativeBatchNormBackward0]
	139954294141136 -> 139954294142432
	139954294141136 [label=AddBackward0]
	139954293940288 -> 139954294141136
	139954293940288 [label=MinkowskiConvolutionFunctionBackward]
	139954294142720 -> 139954293940288
	139954294142720 [label=ReluBackward0]
	139954294142864 -> 139954294142720
	139954294142864 [label=NativeBatchNormBackward0]
	139954395455056 -> 139954294142864
	139954395455056 [label=MinkowskiConvolutionFunctionBackward]
	139954294143104 -> 139954395455056
	139954294143104 [label=ReluBackward0]
	139954294143248 -> 139954294143104
	139954294143248 [label=NativeBatchNormBackward0]
	139954395454816 -> 139954294143248
	139954395454816 [label=MinkowskiConvolutionFunctionBackward]
	139954294143488 -> 139954395454816
	139954294143488 [label=ReluBackward0]
	139954294143632 -> 139954294143488
	139954294143632 [label=NativeBatchNormBackward0]
	139954294123584 -> 139954294143632
	139954294143728 -> 139954294143632
	139954426883264 [label="encoder.unet.1.u.u.u.u.u.conv.0.bn.weight
 (48)" fillcolor=lightblue]
	139954426883264 -> 139954294143728
	139954294143728 [label=AccumulateGrad]
	139954294143680 -> 139954294143632
	139954426883344 [label="encoder.unet.1.u.u.u.u.u.conv.0.bn.bias
 (48)" fillcolor=lightblue]
	139954426883344 -> 139954294143680
	139954294143680 [label=AccumulateGrad]
	139954294143440 -> 139954395454816
	139954426883104 [label="encoder.unet.1.u.u.u.u.u.conv.2.kernel
 (8, 48, 56)" fillcolor=lightblue]
	139954426883104 -> 139954294143440
	139954294143440 [label=AccumulateGrad]
	139954294143344 -> 139954294143248
	139954426482832 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block0.conv_branch.0.bn.weight
 (56)" fillcolor=lightblue]
	139954426482832 -> 139954294143344
	139954294143344 [label=AccumulateGrad]
	139954294143296 -> 139954294143248
	139954426482992 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block0.conv_branch.0.bn.bias
 (56)" fillcolor=lightblue]
	139954426482992 -> 139954294143296
	139954294143296 [label=AccumulateGrad]
	139954294143056 -> 139954395455056
	139954426483392 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block0.conv_branch.2.kernel
 (27, 56, 56)" fillcolor=lightblue]
	139954426483392 -> 139954294143056
	139954294143056 [label=AccumulateGrad]
	139954294142960 -> 139954294142864
	139954426483472 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block0.conv_branch.3.bn.weight
 (56)" fillcolor=lightblue]
	139954426483472 -> 139954294142960
	139954294142960 [label=AccumulateGrad]
	139954294142912 -> 139954294142864
	139954426483552 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block0.conv_branch.3.bn.bias
 (56)" fillcolor=lightblue]
	139954426483552 -> 139954294142912
	139954294142912 [label=AccumulateGrad]
	139954294142576 -> 139954293940288
	139954426483312 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block0.conv_branch.5.kernel
 (27, 56, 56)" fillcolor=lightblue]
	139954426483312 -> 139954294142576
	139954294142576 [label=AccumulateGrad]
	139954395454816 -> 139954294141136
	139954294142528 -> 139954294142432
	139954426484192 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block1.conv_branch.0.bn.weight
 (56)" fillcolor=lightblue]
	139954426484192 -> 139954294142528
	139954294142528 [label=AccumulateGrad]
	139954294142480 -> 139954294142432
	139954426484272 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block1.conv_branch.0.bn.bias
 (56)" fillcolor=lightblue]
	139954426484272 -> 139954294142480
	139954294142480 [label=AccumulateGrad]
	139954294142240 -> 139954293940528
	139954426483872 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block1.conv_branch.2.kernel
 (27, 56, 56)" fillcolor=lightblue]
	139954426483872 -> 139954294142240
	139954294142240 [label=AccumulateGrad]
	139954294142144 -> 139954294141856
	139954426484752 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block1.conv_branch.3.bn.weight
 (56)" fillcolor=lightblue]
	139954426484752 -> 139954294142144
	139954294142144 [label=AccumulateGrad]
	139954294141904 -> 139954294141856
	139954426484832 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block1.conv_branch.3.bn.bias
 (56)" fillcolor=lightblue]
	139954426484832 -> 139954294141904
	139954294141904 [label=AccumulateGrad]
	139954294141712 -> 139954293940768
	139954426484592 [label="encoder.unet.1.u.u.u.u.u.u.blocks.block1.conv_branch.5.kernel
 (27, 56, 56)" fillcolor=lightblue]
	139954426484592 -> 139954294141712
	139954294141712 [label=AccumulateGrad]
	139954294141136 -> 139954294124256
	139954294124208 -> 139954294124496
	139954426485312 [label="encoder.unet.1.u.u.u.u.u.deconv.0.bn.weight
 (56)" fillcolor=lightblue]
	139954426485312 -> 139954294124208
	139954294124208 [label=AccumulateGrad]
	139954294123824 -> 139954294124496
	139954426485392 [label="encoder.unet.1.u.u.u.u.u.deconv.0.bn.bias
 (56)" fillcolor=lightblue]
	139954426485392 -> 139954294123824
	139954294123824 [label=AccumulateGrad]
	139954294123488 -> 139954293941008
	139954426485152 [label="encoder.unet.1.u.u.u.u.u.deconv.2.kernel
 (8, 56, 48)" fillcolor=lightblue]
	139954426485152 -> 139954294123488
	139954294123488 [label=AccumulateGrad]
	139954294123344 -> 139954294123296
	139954426486192 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.conv_branch.0.bn.weight
 (96)" fillcolor=lightblue]
	139954426486192 -> 139954294123344
	139954294123344 [label=AccumulateGrad]
	139954294123200 -> 139954294123296
	139954426486352 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.conv_branch.0.bn.bias
 (96)" fillcolor=lightblue]
	139954426486352 -> 139954294123200
	139954294123200 [label=AccumulateGrad]
	139954294123104 -> 139954293941248
	139954426613824 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.conv_branch.2.kernel
 (27, 96, 48)" fillcolor=lightblue]
	139954426613824 -> 139954294123104
	139954294123104 [label=AccumulateGrad]
	139954294123008 -> 139954294122912
	139954426613904 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.conv_branch.3.bn.weight
 (48)" fillcolor=lightblue]
	139954426613904 -> 139954294123008
	139954294123008 [label=AccumulateGrad]
	139954294122960 -> 139954294122912
	139954426613984 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.conv_branch.3.bn.bias
 (48)" fillcolor=lightblue]
	139954426613984 -> 139954294122960
	139954294122960 [label=AccumulateGrad]
	139954294122720 -> 139954293941488
	139954426614384 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.conv_branch.5.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426614384 -> 139954294122720
	139954294122720 [label=AccumulateGrad]
	139954294122672 -> 139954294121136
	139954294122672 [label=MmBackward0]
	139954294123392 -> 139954294122672
	139954294122816 -> 139954294122672
	139954426485792 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block0.downsample.0.kernel
 (96, 48)" fillcolor=lightblue]
	139954426485792 -> 139954294122816
	139954294122816 [label=AccumulateGrad]
	139954294122528 -> 139954294122432
	139954426614624 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block1.conv_branch.0.bn.weight
 (48)" fillcolor=lightblue]
	139954426614624 -> 139954294122528
	139954294122528 [label=AccumulateGrad]
	139954294122480 -> 139954294122432
	139954426614704 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block1.conv_branch.0.bn.bias
 (48)" fillcolor=lightblue]
	139954426614704 -> 139954294122480
	139954294122480 [label=AccumulateGrad]
	139954294122240 -> 139954293941728
	139954426614304 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block1.conv_branch.2.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426614304 -> 139954294122240
	139954294122240 [label=AccumulateGrad]
	139954294122144 -> 139954294121856
	139954426615184 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block1.conv_branch.3.bn.weight
 (48)" fillcolor=lightblue]
	139954426615184 -> 139954294122144
	139954294122144 [label=AccumulateGrad]
	139954294121904 -> 139954294121856
	139954426615264 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block1.conv_branch.3.bn.bias
 (48)" fillcolor=lightblue]
	139954426615264 -> 139954294121904
	139954294121904 [label=AccumulateGrad]
	139954294121712 -> 139954293941968
	139954426615024 [label="encoder.unet.1.u.u.u.u.u.blocks_tail.block1.conv_branch.5.kernel
 (27, 48, 48)" fillcolor=lightblue]
	139954426615024 -> 139954294121712
	139954294121712 [label=AccumulateGrad]
	139954294121136 -> 139954294120704
	139954294120656 -> 139954294103872
	139954426615744 [label="encoder.unet.1.u.u.u.u.deconv.0.bn.weight
 (48)" fillcolor=lightblue]
	139954426615744 -> 139954294120656
	139954294120656 [label=AccumulateGrad]
	139954294120608 -> 139954294103872
	139954426615824 [label="encoder.unet.1.u.u.u.u.deconv.0.bn.bias
 (48)" fillcolor=lightblue]
	139954426615824 -> 139954294120608
	139954294120608 [label=AccumulateGrad]
	139954294103488 -> 139954293942208
	139954426615584 [label="encoder.unet.1.u.u.u.u.deconv.2.kernel
 (8, 48, 40)" fillcolor=lightblue]
	139954426615584 -> 139954294103488
	139954294103488 [label=AccumulateGrad]
	139954294103344 -> 139954294103296
	139954426616624 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.conv_branch.0.bn.weight
 (80)" fillcolor=lightblue]
	139954426616624 -> 139954294103344
	139954294103344 [label=AccumulateGrad]
	139954294103200 -> 139954294103296
	139954426616704 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.conv_branch.0.bn.bias
 (80)" fillcolor=lightblue]
	139954426616704 -> 139954294103200
	139954294103200 [label=AccumulateGrad]
	139954294103104 -> 139954293942448
	139954426616384 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.conv_branch.2.kernel
 (27, 80, 40)" fillcolor=lightblue]
	139954426616384 -> 139954294103104
	139954294103104 [label=AccumulateGrad]
	139954294103008 -> 139954294102912
	139954426617184 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.conv_branch.3.bn.weight
 (40)" fillcolor=lightblue]
	139954426617184 -> 139954294103008
	139954294103008 [label=AccumulateGrad]
	139954294102960 -> 139954294102912
	139954426617264 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.conv_branch.3.bn.bias
 (40)" fillcolor=lightblue]
	139954426617264 -> 139954294102960
	139954294102960 [label=AccumulateGrad]
	139954294102720 -> 139954293942688
	139954426617024 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.conv_branch.5.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426617024 -> 139954294102720
	139954294102720 [label=AccumulateGrad]
	139954294102672 -> 139954294101136
	139954294102672 [label=MmBackward0]
	139954294103392 -> 139954294102672
	139954294102816 -> 139954294102672
	139954426616224 [label="encoder.unet.1.u.u.u.u.blocks_tail.block0.downsample.0.kernel
 (80, 40)" fillcolor=lightblue]
	139954426616224 -> 139954294102816
	139954294102816 [label=AccumulateGrad]
	139954294102528 -> 139954294102432
	139954426228880 [label="encoder.unet.1.u.u.u.u.blocks_tail.block1.conv_branch.0.bn.weight
 (40)" fillcolor=lightblue]
	139954426228880 -> 139954294102528
	139954294102528 [label=AccumulateGrad]
	139954294102480 -> 139954294102432
	139954426228960 [label="encoder.unet.1.u.u.u.u.blocks_tail.block1.conv_branch.0.bn.bias
 (40)" fillcolor=lightblue]
	139954426228960 -> 139954294102480
	139954294102480 [label=AccumulateGrad]
	139954294102240 -> 139954293942928
	139954426229360 [label="encoder.unet.1.u.u.u.u.blocks_tail.block1.conv_branch.2.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426229360 -> 139954294102240
	139954294102240 [label=AccumulateGrad]
	139954294102144 -> 139954294101856
	139954426229440 [label="encoder.unet.1.u.u.u.u.blocks_tail.block1.conv_branch.3.bn.weight
 (40)" fillcolor=lightblue]
	139954426229440 -> 139954294102144
	139954294102144 [label=AccumulateGrad]
	139954294101904 -> 139954294101856
	139954426229520 [label="encoder.unet.1.u.u.u.u.blocks_tail.block1.conv_branch.3.bn.bias
 (40)" fillcolor=lightblue]
	139954426229520 -> 139954294101904
	139954294101904 [label=AccumulateGrad]
	139954294101712 -> 139954293943168
	139954426229280 [label="encoder.unet.1.u.u.u.u.blocks_tail.block1.conv_branch.5.kernel
 (27, 40, 40)" fillcolor=lightblue]
	139954426229280 -> 139954294101712
	139954294101712 [label=AccumulateGrad]
	139954294101136 -> 139954294100704
	139954294100656 -> 139954294100992
	139954426230000 [label="encoder.unet.1.u.u.u.deconv.0.bn.weight
 (40)" fillcolor=lightblue]
	139954426230000 -> 139954294100656
	139954294100656 [label=AccumulateGrad]
	139954294100272 -> 139954294100992
	139954426230080 [label="encoder.unet.1.u.u.u.deconv.0.bn.bias
 (40)" fillcolor=lightblue]
	139954426230080 -> 139954294100272
	139954294100272 [label=AccumulateGrad]
	139954294100032 -> 139954293943408
	139954426229840 [label="encoder.unet.1.u.u.u.deconv.2.kernel
 (8, 40, 32)" fillcolor=lightblue]
	139954426229840 -> 139954294100032
	139954294100032 [label=AccumulateGrad]
	139954294083344 -> 139954294083296
	139954426230880 [label="encoder.unet.1.u.u.u.blocks_tail.block0.conv_branch.0.bn.weight
 (64)" fillcolor=lightblue]
	139954426230880 -> 139954294083344
	139954294083344 [label=AccumulateGrad]
	139954294083200 -> 139954294083296
	139954426230960 [label="encoder.unet.1.u.u.u.blocks_tail.block0.conv_branch.0.bn.bias
 (64)" fillcolor=lightblue]
	139954426230960 -> 139954294083200
	139954294083200 [label=AccumulateGrad]
	139954294083104 -> 139954293943648
	139954426230640 [label="encoder.unet.1.u.u.u.blocks_tail.block0.conv_branch.2.kernel
 (27, 64, 32)" fillcolor=lightblue]
	139954426230640 -> 139954294083104
	139954294083104 [label=AccumulateGrad]
	139954294083008 -> 139954294082912
	139954426231440 [label="encoder.unet.1.u.u.u.blocks_tail.block0.conv_branch.3.bn.weight
 (32)" fillcolor=lightblue]
	139954426231440 -> 139954294083008
	139954294083008 [label=AccumulateGrad]
	139954294082960 -> 139954294082912
	139954426231520 [label="encoder.unet.1.u.u.u.blocks_tail.block0.conv_branch.3.bn.bias
 (32)" fillcolor=lightblue]
	139954426231520 -> 139954294082960
	139954294082960 [label=AccumulateGrad]
	139954294082720 -> 139954293943888
	139954426231280 [label="encoder.unet.1.u.u.u.blocks_tail.block0.conv_branch.5.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954426231280 -> 139954294082720
	139954294082720 [label=AccumulateGrad]
	139954294082672 -> 139954294081136
	139954294082672 [label=MmBackward0]
	139954294083392 -> 139954294082672
	139954294082816 -> 139954294082672
	139954426230480 [label="encoder.unet.1.u.u.u.blocks_tail.block0.downsample.0.kernel
 (64, 32)" fillcolor=lightblue]
	139954426230480 -> 139954294082816
	139954294082816 [label=AccumulateGrad]
	139954294082528 -> 139954294082432
	139954426232160 [label="encoder.unet.1.u.u.u.blocks_tail.block1.conv_branch.0.bn.weight
 (32)" fillcolor=lightblue]
	139954426232160 -> 139954294082528
	139954294082528 [label=AccumulateGrad]
	139954294082480 -> 139954294082432
	139954426232240 [label="encoder.unet.1.u.u.u.blocks_tail.block1.conv_branch.0.bn.bias
 (32)" fillcolor=lightblue]
	139954426232240 -> 139954294082480
	139954294082480 [label=AccumulateGrad]
	139954294082240 -> 139954293948480
	139954426231840 [label="encoder.unet.1.u.u.u.blocks_tail.block1.conv_branch.2.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954426231840 -> 139954294082240
	139954294082240 [label=AccumulateGrad]
	139954294082144 -> 139954294081856
	139954426232720 [label="encoder.unet.1.u.u.u.blocks_tail.block1.conv_branch.3.bn.weight
 (32)" fillcolor=lightblue]
	139954426232720 -> 139954294082144
	139954294082144 [label=AccumulateGrad]
	139954294081904 -> 139954294081856
	139954426372160 [label="encoder.unet.1.u.u.u.blocks_tail.block1.conv_branch.3.bn.bias
 (32)" fillcolor=lightblue]
	139954426372160 -> 139954294081904
	139954294081904 [label=AccumulateGrad]
	139954294081712 -> 139954293948720
	139954426372560 [label="encoder.unet.1.u.u.u.blocks_tail.block1.conv_branch.5.kernel
 (27, 32, 32)" fillcolor=lightblue]
	139954426372560 -> 139954294081712
	139954294081712 [label=AccumulateGrad]
	139954294081136 -> 139954294080704
	139954294080656 -> 139954294080992
	139954426372640 [label="encoder.unet.1.u.u.deconv.0.bn.weight
 (32)" fillcolor=lightblue]
	139954426372640 -> 139954294080656
	139954294080656 [label=AccumulateGrad]
	139954294080368 -> 139954294080992
	139954426372720 [label="encoder.unet.1.u.u.deconv.0.bn.bias
 (32)" fillcolor=lightblue]
	139954426372720 -> 139954294080368
	139954294080368 [label=AccumulateGrad]
	139954294079888 -> 139954293948960
	139954426372480 [label="encoder.unet.1.u.u.deconv.2.kernel
 (8, 32, 24)" fillcolor=lightblue]
	139954426372480 -> 139954294079888
	139954294079888 [label=AccumulateGrad]
	139954294079744 -> 139954294079696
	139954426373520 [label="encoder.unet.1.u.u.blocks_tail.block0.conv_branch.0.bn.weight
 (48)" fillcolor=lightblue]
	139954426373520 -> 139954294079744
	139954294079744 [label=AccumulateGrad]
	139954294079600 -> 139954294079696
	139954426373600 [label="encoder.unet.1.u.u.blocks_tail.block0.conv_branch.0.bn.bias
 (48)" fillcolor=lightblue]
	139954426373600 -> 139954294079600
	139954294079600 [label=AccumulateGrad]
	139954294067104 -> 139954293949200
	139954426373280 [label="encoder.unet.1.u.u.blocks_tail.block0.conv_branch.2.kernel
 (27, 48, 24)" fillcolor=lightblue]
	139954426373280 -> 139954294067104
	139954294067104 [label=AccumulateGrad]
	139954294067056 -> 139954294066960
	139954426374080 [label="encoder.unet.1.u.u.blocks_tail.block0.conv_branch.3.bn.weight
 (24)" fillcolor=lightblue]
	139954426374080 -> 139954294067056
	139954294067056 [label=AccumulateGrad]
	139954294067008 -> 139954294066960
	139954426374160 [label="encoder.unet.1.u.u.blocks_tail.block0.conv_branch.3.bn.bias
 (24)" fillcolor=lightblue]
	139954426374160 -> 139954294067008
	139954294067008 [label=AccumulateGrad]
	139954294066768 -> 139954293949440
	139954426373920 [label="encoder.unet.1.u.u.blocks_tail.block0.conv_branch.5.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954426373920 -> 139954294066768
	139954294066768 [label=AccumulateGrad]
	139954294066720 -> 139954294065184
	139954294066720 [label=MmBackward0]
	139954294079792 -> 139954294066720
	139954294066912 -> 139954294066720
	139954426373120 [label="encoder.unet.1.u.u.blocks_tail.block0.downsample.0.kernel
 (48, 24)" fillcolor=lightblue]
	139954426373120 -> 139954294066912
	139954294066912 [label=AccumulateGrad]
	139954294066576 -> 139954294066480
	139954426374800 [label="encoder.unet.1.u.u.blocks_tail.block1.conv_branch.0.bn.weight
 (24)" fillcolor=lightblue]
	139954426374800 -> 139954294066576
	139954294066576 [label=AccumulateGrad]
	139954294066528 -> 139954294066480
	139954426374880 [label="encoder.unet.1.u.u.blocks_tail.block1.conv_branch.0.bn.bias
 (24)" fillcolor=lightblue]
	139954426374880 -> 139954294066528
	139954294066528 [label=AccumulateGrad]
	139954294066288 -> 139954293949680
	139954426374480 [label="encoder.unet.1.u.u.blocks_tail.block1.conv_branch.2.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954426374480 -> 139954294066288
	139954294066288 [label=AccumulateGrad]
	139954294066192 -> 139954294065904
	139954426375360 [label="encoder.unet.1.u.u.blocks_tail.block1.conv_branch.3.bn.weight
 (24)" fillcolor=lightblue]
	139954426375360 -> 139954294066192
	139954294066192 [label=AccumulateGrad]
	139954294065952 -> 139954294065904
	139954426375440 [label="encoder.unet.1.u.u.blocks_tail.block1.conv_branch.3.bn.bias
 (24)" fillcolor=lightblue]
	139954426375440 -> 139954294065952
	139954294065952 [label=AccumulateGrad]
	139954294065760 -> 139954293949920
	139954426375200 [label="encoder.unet.1.u.u.blocks_tail.block1.conv_branch.5.kernel
 (27, 24, 24)" fillcolor=lightblue]
	139954426375200 -> 139954294065760
	139954294065760 [label=AccumulateGrad]
	139954294065184 -> 139954294064752
	139954294064704 -> 139954294065040
	139954426375920 [label="encoder.unet.1.u.deconv.0.bn.weight
 (24)" fillcolor=lightblue]
	139954426375920 -> 139954294064704
	139954294064704 [label=AccumulateGrad]
	139954294064320 -> 139954294065040
	139954426376000 [label="encoder.unet.1.u.deconv.0.bn.bias
 (24)" fillcolor=lightblue]
	139954426376000 -> 139954294064320
	139954294064320 [label=AccumulateGrad]
	139954294063984 -> 139954293950160
	139954425987456 [label="encoder.unet.1.u.deconv.2.kernel
 (8, 24, 16)" fillcolor=lightblue]
	139954425987456 -> 139954294063984
	139954294063984 [label=AccumulateGrad]
	139954294063840 -> 139954294063792
	139954425987776 [label="encoder.unet.1.u.blocks_tail.block0.conv_branch.0.bn.weight
 (32)" fillcolor=lightblue]
	139954425987776 -> 139954294063840
	139954294063840 [label=AccumulateGrad]
	139954294063696 -> 139954294063792
	139954425987856 [label="encoder.unet.1.u.blocks_tail.block0.conv_branch.0.bn.bias
 (32)" fillcolor=lightblue]
	139954425987856 -> 139954294063696
	139954294063696 [label=AccumulateGrad]
	139954294063600 -> 139954293950400
	139954425987536 [label="encoder.unet.1.u.blocks_tail.block0.conv_branch.2.kernel
 (27, 32, 16)" fillcolor=lightblue]
	139954425987536 -> 139954294063600
	139954294063600 [label=AccumulateGrad]
	139954294063504 -> 139954294063408
	139954425988336 [label="encoder.unet.1.u.blocks_tail.block0.conv_branch.3.bn.weight
 (16)" fillcolor=lightblue]
	139954425988336 -> 139954294063504
	139954294063504 [label=AccumulateGrad]
	139954294063456 -> 139954294063408
	139954425988416 [label="encoder.unet.1.u.blocks_tail.block0.conv_branch.3.bn.bias
 (16)" fillcolor=lightblue]
	139954425988416 -> 139954294063456
	139954294063456 [label=AccumulateGrad]
	139954294063216 -> 139954293950640
	139954425988176 [label="encoder.unet.1.u.blocks_tail.block0.conv_branch.5.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954425988176 -> 139954294063216
	139954294063216 [label=AccumulateGrad]
	139954294042576 -> 139954294040128
	139954294042576 [label=MmBackward0]
	139954294063888 -> 139954294042576
	139954294063312 -> 139954294042576
	139954425987376 [label="encoder.unet.1.u.blocks_tail.block0.downsample.0.kernel
 (32, 16)" fillcolor=lightblue]
	139954425987376 -> 139954294063312
	139954294063312 [label=AccumulateGrad]
	139954294042480 -> 139954294042384
	139954425989056 [label="encoder.unet.1.u.blocks_tail.block1.conv_branch.0.bn.weight
 (16)" fillcolor=lightblue]
	139954425989056 -> 139954294042480
	139954294042480 [label=AccumulateGrad]
	139954294042432 -> 139954294042384
	139954425989136 [label="encoder.unet.1.u.blocks_tail.block1.conv_branch.0.bn.bias
 (16)" fillcolor=lightblue]
	139954425989136 -> 139954294042432
	139954294042432 [label=AccumulateGrad]
	139954294042288 -> 139954293950880
	139954425988736 [label="encoder.unet.1.u.blocks_tail.block1.conv_branch.2.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954425988736 -> 139954294042288
	139954294042288 [label=AccumulateGrad]
	139954294041808 -> 139954294040992
	139954425989616 [label="encoder.unet.1.u.blocks_tail.block1.conv_branch.3.bn.weight
 (16)" fillcolor=lightblue]
	139954425989616 -> 139954294041808
	139954294041808 [label=AccumulateGrad]
	139954294040896 -> 139954294040992
	139954425989696 [label="encoder.unet.1.u.blocks_tail.block1.conv_branch.3.bn.bias
 (16)" fillcolor=lightblue]
	139954425989696 -> 139954294040896
	139954294040896 [label=AccumulateGrad]
	139954294040704 -> 139954293951120
	139954425989456 [label="encoder.unet.1.u.blocks_tail.block1.conv_branch.5.kernel
 (27, 16, 16)" fillcolor=lightblue]
	139954425989456 -> 139954294040704
	139954294040704 [label=AccumulateGrad]
	139954294040128 -> 139954294039696
	139954294039648 -> 139954294039984
	139954425990176 [label="encoder.unet.1.deconv.0.bn.weight
 (16)" fillcolor=lightblue]
	139954425990176 -> 139954294039648
	139954294039648 [label=AccumulateGrad]
	139954294039264 -> 139954294039984
	139954425990256 [label="encoder.unet.1.deconv.0.bn.bias
 (16)" fillcolor=lightblue]
	139954425990256 -> 139954294039264
	139954294039264 [label=AccumulateGrad]
	139954294038928 -> 139954293951360
	139954425990016 [label="encoder.unet.1.deconv.2.kernel
 (8, 16, 8)" fillcolor=lightblue]
	139954425990016 -> 139954294038928
	139954294038928 [label=AccumulateGrad]
	139954294038784 -> 139954294038736
	139954425991056 [label="encoder.unet.1.blocks_tail.block0.conv_branch.0.bn.weight
 (16)" fillcolor=lightblue]
	139954425991056 -> 139954294038784
	139954294038784 [label=AccumulateGrad]
	139954294038640 -> 139954294038736
	139954426130496 [label="encoder.unet.1.blocks_tail.block0.conv_branch.0.bn.bias
 (16)" fillcolor=lightblue]
	139954426130496 -> 139954294038640
	139954294038640 [label=AccumulateGrad]
	139954396721056 -> 139954293951600
	139954426130896 [label="encoder.unet.1.blocks_tail.block0.conv_branch.2.kernel
 (27, 16, 8)" fillcolor=lightblue]
	139954426130896 -> 139954396721056
	139954396721056 [label=AccumulateGrad]
	139954396721008 -> 139954396720912
	139954426130976 [label="encoder.unet.1.blocks_tail.block0.conv_branch.3.bn.weight
 (8)" fillcolor=lightblue]
	139954426130976 -> 139954396721008
	139954396721008 [label=AccumulateGrad]
	139954396720960 -> 139954396720912
	139954426131056 [label="encoder.unet.1.blocks_tail.block0.conv_branch.3.bn.bias
 (8)" fillcolor=lightblue]
	139954426131056 -> 139954396720960
	139954396720960 [label=AccumulateGrad]
	139954396720720 -> 139954293951840
	139954426130816 [label="encoder.unet.1.blocks_tail.block0.conv_branch.5.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954426130816 -> 139954396720720
	139954396720720 [label=AccumulateGrad]
	139954396720672 -> 139954396719808
	139954396720672 [label=MmBackward0]
	139954294038832 -> 139954396720672
	139954396720864 -> 139954396720672
	139954425990656 [label="encoder.unet.1.blocks_tail.block0.downsample.0.kernel
 (16, 8)" fillcolor=lightblue]
	139954425990656 -> 139954396720864
	139954396720864 [label=AccumulateGrad]
	139954396720528 -> 139954396720432
	139954426131696 [label="encoder.unet.1.blocks_tail.block1.conv_branch.0.bn.weight
 (8)" fillcolor=lightblue]
	139954426131696 -> 139954396720528
	139954396720528 [label=AccumulateGrad]
	139954396720480 -> 139954396720432
	139954426131776 [label="encoder.unet.1.blocks_tail.block1.conv_branch.0.bn.bias
 (8)" fillcolor=lightblue]
	139954426131776 -> 139954396720480
	139954396720480 [label=AccumulateGrad]
	139954396720240 -> 139954293952080
	139954426131376 [label="encoder.unet.1.blocks_tail.block1.conv_branch.2.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954426131376 -> 139954396720240
	139954396720240 [label=AccumulateGrad]
	139954396720144 -> 139954396720048
	139954426132256 [label="encoder.unet.1.blocks_tail.block1.conv_branch.3.bn.weight
 (8)" fillcolor=lightblue]
	139954426132256 -> 139954396720144
	139954396720144 [label=AccumulateGrad]
	139954396720096 -> 139954396720048
	139954426132336 [label="encoder.unet.1.blocks_tail.block1.conv_branch.3.bn.bias
 (8)" fillcolor=lightblue]
	139954426132336 -> 139954396720096
	139954396720096 [label=AccumulateGrad]
	139954396719856 -> 139954293956672
	139954426132096 [label="encoder.unet.1.blocks_tail.block1.conv_branch.5.kernel
 (27, 8, 8)" fillcolor=lightblue]
	139954426132096 -> 139954396719856
	139954396719856 [label=AccumulateGrad]
	139954396719808 -> 139954396719616
	139954396719568 -> 139954396719424
	139954293955696 [label="
 (8)" fillcolor=lightblue]
	139954293955696 -> 139954396719568
	139954396719568 [label=AccumulateGrad]
	139954396719520 -> 139954396719424
	139954293956416 [label="
 (8)" fillcolor=lightblue]
	139954293956416 -> 139954396719520
	139954396719520 [label=AccumulateGrad]
	139954396718464 -> 139954396719232
	139954396718464 [label=TBackward0]
	139954396719760 -> 139954396718464
	139954425709328 [label="udf_decoder.per_scale_in.0.0.weight
 (8, 8)" fillcolor=lightblue]
	139954425709328 -> 139954396719760
	139954396719760 [label=AccumulateGrad]
	139954396718224 -> 139954396718080
	139954396718224 [label=SoftmaxBackward0]
	139954396718992 -> 139954396718224
	139954396718992 [label=ViewBackward0]
	139954396719088 -> 139954396718992
	139954396719088 [label=AddmmBackward0]
	139954396719376 -> 139954396719088
	139954425709808 [label="udf_decoder.per_scale_att_pooling.0.fc.bias
 (71)" fillcolor=lightblue]
	139954425709808 -> 139954396719376
	139954396719376 [label=AccumulateGrad]
	139954396719184 -> 139954396719088
	139954396719184 [label=ViewBackward0]
	139954396718512 -> 139954396719184
	139954396718656 -> 139954396719088
	139954396718656 [label=TBackward0]
	139954396719472 -> 139954396718656
	139954425709648 [label="udf_decoder.per_scale_att_pooling.0.fc.weight
 (71, 71)" fillcolor=lightblue]
	139954425709648 -> 139954396719472
	139954396719472 [label=AccumulateGrad]
	139954396717408 -> 139954396717456
	139954425772448 [label="udf_decoder.per_scale_att_pooling.0.mlp.conv.weight
 (71, 71, 1)" fillcolor=lightblue]
	139954425772448 -> 139954396717408
	139954396717408 [label=AccumulateGrad]
	139954396718752 -> 139954396717984
	139954425772688 [label="udf_decoder.per_scale_att_pooling.0.mlp.bn.bn.weight
 (71)" fillcolor=lightblue]
	139954425772688 -> 139954396718752
	139954396718752 [label=AccumulateGrad]
	139954396717120 -> 139954396717984
	139954425772848 [label="udf_decoder.per_scale_att_pooling.0.mlp.bn.bn.bias
 (71)" fillcolor=lightblue]
	139954425772848 -> 139954396717120
	139954396717120 [label=AccumulateGrad]
	139954427614496 -> 139954427653424
	139954427614496 [label=TBackward0]
	139954427616272 -> 139954427614496
	139954425773728 [label="udf_decoder.per_scale_out.0.in_layer.0.weight
 (32, 71)" fillcolor=lightblue]
	139954425773728 -> 139954427616272
	139954427616272 [label=AccumulateGrad]
	139954427653088 -> 139954427652608
	139954427653088 [label=TBackward0]
	139954427614016 -> 139954427653088
	139954425806912 [label="udf_decoder.per_scale_out.0.before_skip.0.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425806912 -> 139954427614016
	139954427614016 [label=AccumulateGrad]
	139954427653184 -> 139954427650976
	139954427653184 [label=TBackward0]
	139954427614208 -> 139954427653184
	139954425807152 [label="udf_decoder.per_scale_out.0.before_skip.1.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425807152 -> 139954427614208
	139954427614208 [label=AccumulateGrad]
	139954427651216 -> 139954427650784
	139954427651216 [label=LeakyReluBackward1]
	139954427652944 -> 139954427651216
	139954427652944 [label=AddmmBackward0]
	139954427650304 -> 139954427652944
	139954425773968 [label="udf_decoder.per_scale_out.0.skip_proj.0.bias
 (32)" fillcolor=lightblue]
	139954425773968 -> 139954427650304
	139954427650304 [label=AccumulateGrad]
	139954427613488 -> 139954427652944
	139954427653328 -> 139954427652944
	139954427653328 [label=TBackward0]
	139954396717744 -> 139954427653328
	139954425773888 [label="udf_decoder.per_scale_out.0.skip_proj.0.weight
 (32, 71)" fillcolor=lightblue]
	139954425773888 -> 139954396717744
	139954396717744 [label=AccumulateGrad]
	139954427651264 -> 139954427650592
	139954427651264 [label=TBackward0]
	139954427651984 -> 139954427651264
	139954425807312 [label="udf_decoder.per_scale_out.0.after_skip.0.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425807312 -> 139954427651984
	139954427651984 [label=AccumulateGrad]
	139954427575936 -> 139954427587696
	139954427575936 [label=TBackward0]
	139954427652704 -> 139954427575936
	139954425807552 [label="udf_decoder.per_scale_out.0.after_skip.1.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425807552 -> 139954427652704
	139954427652704 [label=AccumulateGrad]
	139954427587984 -> 139954427588176
	139954427587984 [label=TBackward0]
	139954427588128 -> 139954427587984
	139954425807712 [label="udf_decoder.out.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425807712 -> 139954427588128
	139954427588128 [label=AccumulateGrad]
	139954427587168 -> 139954427586208
	139954427587168 [label=TBackward0]
	139954427588080 -> 139954427587168
	139954425807872 [label="udf_decoder.out.1.weight
 (1, 32)" fillcolor=lightblue]
	139954425807872 -> 139954427588080
	139954427588080 [label=AccumulateGrad]
	139954427585200 -> 139954427586976
	139954427585200 [label=MulBackward0]
	139954427586496 -> 139954427585200
	139954427586496 [label=MeanBackward0]
	139954427585680 -> 139954427586496
	139954427585680 [label=AbsBackward0]
	139954427588464 -> 139954427585680
	139954427588464 [label=SqueezeBackward1]
	139954427587888 -> 139954427588464
	139954427587888 [label=TanhBackward0]
	139954427653568 -> 139954427587888
	139954427653568 [label=AddmmBackward0]
	139954427584816 -> 139954427653568
	139954427653136 -> 139954427653568
	139954427653136 [label=AddmmBackward0]
	139954427586736 -> 139954427653136
	139954396718128 -> 139954427653136
	139954396718128 [label=CatBackward0]
	139954396719664 -> 139954396718128
	139954396719664 [label=LeakyReluBackward1]
	139954396720000 -> 139954396719664
	139954396720000 [label=AddmmBackward0]
	139954427574640 -> 139954396720000
	139954396720192 -> 139954396720000
	139954396720192 [label=LeakyReluBackward1]
	139954396720384 -> 139954396720192
	139954396720384 [label=AddmmBackward0]
	139954427652128 -> 139954396720384
	139954396720576 -> 139954396720384
	139954396720576 [label=AddBackward0]
	139954294038880 -> 139954396720576
	139954294038880 [label=LeakyReluBackward1]
	139954294040080 -> 139954294038880
	139954294040080 [label=AddmmBackward0]
	139954427652416 -> 139954294040080
	139954294039312 -> 139954294040080
	139954294039312 [label=LeakyReluBackward1]
	139954294040512 -> 139954294039312
	139954294040512 [label=AddmmBackward0]
	139954427650352 -> 139954294040512
	139954294042528 -> 139954294040512
	139954294042528 [label=LeakyReluBackward1]
	139954294042144 -> 139954294042528
	139954294042144 [label=AddmmBackward0]
	139954427653808 -> 139954294042144
	139954294063360 -> 139954294042144
	139954294063360 [label=SqueezeBackward1]
	139954294063744 -> 139954294063360
	139954294063744 [label=TransposeBackward0]
	139954294065136 -> 139954294063744
	139954294065136 [label=LeakyReluBackward1]
	139954294064368 -> 139954294065136
	139954294064368 [label=CudnnBatchNormBackward0]
	139954294066240 -> 139954294064368
	139954294066240 [label=ConvolutionBackward0]
	139954294066144 -> 139954294066240
	139954294066144 [label=TransposeBackward0]
	139954294066384 -> 139954294066144
	139954294066384 [label=SumBackward1]
	139954294066864 -> 139954294066384
	139954294066864 [label=MulBackward0]
	139954294066624 -> 139954294066864
	139954294066624 [label=IndexPutBackward0]
	139954294079648 -> 139954294066624
	139954294079648 [label=CatBackward0]
	139954294081088 -> 139954294079648
	139954294081088 [label=IndexBackward0]
	139954294080224 -> 139954294081088
	139954294080224 [label=CatBackward0]
	139954294082192 -> 139954294080224
	139954294082192 [label=IndexBackward0]
	139954294082096 -> 139954294082192
	139954294082096 [label=ReluBackward0]
	139954294082336 -> 139954294082096
	139954294082336 [label=AddmmBackward0]
	139954396719328 -> 139954294082336
	139954396719280 -> 139954294082336
	139954294083056 -> 139954294082336
	139954294083056 [label=TBackward0]
	139954396719760 -> 139954294083056
	139954294063168 -> 139954294066864
	139954294063168 [label=SoftmaxBackward0]
	139954294080944 -> 139954294063168
	139954294080944 [label=ViewBackward0]
	139954294081520 -> 139954294080944
	139954294081520 [label=AddmmBackward0]
	139954396719376 -> 139954294081520
	139954294082384 -> 139954294081520
	139954294082384 [label=ViewBackward0]
	139954294066624 -> 139954294082384
	139954294082624 -> 139954294081520
	139954294082624 [label=TBackward0]
	139954396719472 -> 139954294082624
	139954396717408 -> 139954294066240
	139954396718752 -> 139954294064368
	139954396717120 -> 139954294064368
	139954294064032 -> 139954294042144
	139954294064032 [label=TBackward0]
	139954427616272 -> 139954294064032
	139954294041184 -> 139954294040512
	139954294041184 [label=TBackward0]
	139954427614016 -> 139954294041184
	139954294039936 -> 139954294040080
	139954294039936 [label=TBackward0]
	139954427614208 -> 139954294039936
	139954294038592 -> 139954396720576
	139954294038592 [label=LeakyReluBackward1]
	139954294041904 -> 139954294038592
	139954294041904 [label=AddmmBackward0]
	139954427650304 -> 139954294041904
	139954294063360 -> 139954294041904
	139954294042336 -> 139954294041904
	139954294042336 [label=TBackward0]
	139954396717744 -> 139954294042336
	139954396720816 -> 139954396720384
	139954396720816 [label=TBackward0]
	139954427651984 -> 139954396720816
	139954396719952 -> 139954396720000
	139954396719952 [label=TBackward0]
	139954427652704 -> 139954396719952
	139954396717264 -> 139954427653136
	139954396717264 [label=TBackward0]
	139954427588128 -> 139954396717264
	139954396717600 -> 139954427653568
	139954396717600 [label=TBackward0]
	139954427588080 -> 139954396717600
	139954427584576 -> 139954398102000
	139954427584576 [label=MulBackward0]
	139954427586256 -> 139954427584576
	139954427586256 [label=MeanBackward0]
	139954427588272 -> 139954427586256
	139954427588272 [label=PowBackward0]
	139954427651408 -> 139954427588272
	139954427651408 [label=SubBackward0]
	139954396718848 -> 139954427651408
	139954396718848 [label=CopyBackwards]
	139954396718944 -> 139954396718848
	139954396718944 [label=NormBackward1]
	139954396720336 -> 139954396718944
	139954396720336 [label=StackBackward0]
	139954396718320 -> 139954396720336
	139954396718320 [label=DivBackward0]
	139954294039072 -> 139954396718320
	139954294039072 [label=SubBackward0]
	139954294063936 -> 139954294039072
	139954294063936 [label=SqueezeBackward1]
	139954294066672 -> 139954294063936
	139954294066672 [label=TanhBackward0]
	139954294066432 -> 139954294066672
	139954294066432 [label=AddmmBackward0]
	139954427584816 -> 139954294066432
	139954294081328 -> 139954294066432
	139954294081328 [label=AddmmBackward0]
	139954427586736 -> 139954294081328
	139954294083488 -> 139954294081328
	139954294083488 [label=CatBackward0]
	139954294083440 -> 139954294083488
	139954294083440 [label=LeakyReluBackward1]
	139954294083248 -> 139954294083440
	139954294083248 [label=AddmmBackward0]
	139954427574640 -> 139954294083248
	139954294100944 -> 139954294083248
	139954294100944 [label=LeakyReluBackward1]
	139954294102192 -> 139954294100944
	139954294102192 [label=AddmmBackward0]
	139954427652128 -> 139954294102192
	139954294102096 -> 139954294102192
	139954294102096 [label=AddBackward0]
	139954294102384 -> 139954294102096
	139954294102384 [label=LeakyReluBackward1]
	139954294102864 -> 139954294102384
	139954294102864 [label=AddmmBackward0]
	139954427652416 -> 139954294102864
	139954294103440 -> 139954294102864
	139954294103440 [label=LeakyReluBackward1]
	139954294103632 -> 139954294103440
	139954294103632 [label=AddmmBackward0]
	139954427650352 -> 139954294103632
	139954294120992 -> 139954294103632
	139954294120992 [label=LeakyReluBackward1]
	139954294121520 -> 139954294120992
	139954294121520 [label=AddmmBackward0]
	139954427653808 -> 139954294121520
	139954294122624 -> 139954294121520
	139954294122624 [label=SqueezeBackward1]
	139954294123056 -> 139954294122624
	139954294123056 [label=TransposeBackward0]
	139954294122864 -> 139954294123056
	139954294122864 [label=LeakyReluBackward1]
	139954294123440 -> 139954294122864
	139954294123440 [label=CudnnBatchNormBackward0]
	139954294123632 -> 139954294123440
	139954294123632 [label=ConvolutionBackward0]
	139954294123872 -> 139954294123632
	139954294123872 [label=TransposeBackward0]
	139954294141328 -> 139954294123872
	139954294141328 [label=SumBackward1]
	139954294141520 -> 139954294141328
	139954294141520 [label=MulBackward0]
	139954294142672 -> 139954294141520
	139954294142672 [label=IndexPutBackward0]
	139954294142624 -> 139954294142672
	139954294142624 [label=CatBackward0]
	139954294142768 -> 139954294142624
	139954294142768 [label=IndexBackward0]
	139954294143392 -> 139954294142768
	139954294143392 [label=CatBackward0]
	139954294143200 -> 139954294143392
	139954294143200 [label=IndexBackward0]
	139954294143776 -> 139954294143200
	139954294143776 [label=ReluBackward0]
	139954294143872 -> 139954294143776
	139954294143872 [label=AddmmBackward0]
	139954396719328 -> 139954294143872
	139954396719280 -> 139954294143872
	139954294143968 -> 139954294143872
	139954294143968 [label=TBackward0]
	139954396719760 -> 139954294143968
	139954294142096 -> 139954294141520
	139954294142096 [label=SoftmaxBackward0]
	139954294142816 -> 139954294142096
	139954294142816 [label=ViewBackward0]
	139954294143824 -> 139954294142816
	139954294143824 [label=AddmmBackward0]
	139954396719376 -> 139954294143824
	139954294143920 -> 139954294143824
	139954294143920 [label=ViewBackward0]
	139954294142672 -> 139954294143920
	139954294143536 -> 139954294143824
	139954294143536 [label=TBackward0]
	139954396719472 -> 139954294143536
	139954396717408 -> 139954294123632
	139954396718752 -> 139954294123440
	139954396717120 -> 139954294123440
	139954294122096 -> 139954294121520
	139954294122096 [label=TBackward0]
	139954427616272 -> 139954294122096
	139954294120944 -> 139954294103632
	139954294120944 [label=TBackward0]
	139954427614016 -> 139954294120944
	139954294102576 -> 139954294102864
	139954294102576 [label=TBackward0]
	139954427614208 -> 139954294102576
	139954294102336 -> 139954294102096
	139954294102336 [label=LeakyReluBackward1]
	139954294103248 -> 139954294102336
	139954294103248 [label=AddmmBackward0]
	139954427650304 -> 139954294103248
	139954294122624 -> 139954294103248
	139954294103536 -> 139954294103248
	139954294103536 [label=TBackward0]
	139954396717744 -> 139954294103536
	139954294101520 -> 139954294102192
	139954294101520 [label=TBackward0]
	139954427651984 -> 139954294101520
	139954294101088 -> 139954294083248
	139954294101088 [label=TBackward0]
	139954427652704 -> 139954294101088
	139954294082864 -> 139954294081328
	139954294082864 [label=TBackward0]
	139954427588128 -> 139954294082864
	139954294080032 -> 139954294066432
	139954294080032 [label=TBackward0]
	139954427588080 -> 139954294080032
	139954294064128 -> 139954294039072
	139954294064128 [label=SqueezeBackward1]
	139954294065376 -> 139954294064128
	139954294065376 [label=TanhBackward0]
	139954294079552 -> 139954294065376
	139954294079552 [label=AddmmBackward0]
	139954427584816 -> 139954294079552
	139954294079840 -> 139954294079552
	139954294079840 [label=AddmmBackward0]
	139954427586736 -> 139954294079840
	139954294101328 -> 139954294079840
	139954294101328 [label=CatBackward0]
	139954294102624 -> 139954294101328
	139954294102624 [label=LeakyReluBackward1]
	139954294122576 -> 139954294102624
	139954294122576 [label=AddmmBackward0]
	139954427574640 -> 139954294122576
	139954294122384 -> 139954294122576
	139954294122384 [label=LeakyReluBackward1]
	139954294122336 -> 139954294122384
	139954294122336 [label=AddmmBackward0]
	139954427652128 -> 139954294122336
	139954294141088 -> 139954294122336
	139954294141088 [label=AddBackward0]
	139954294142384 -> 139954294141088
	139954294142384 [label=LeakyReluBackward1]
	139954294142336 -> 139954294142384
	139954294142336 [label=AddmmBackward0]
	139954427652416 -> 139954294142336
	139954294144160 -> 139954294142336
	139954294144160 [label=LeakyReluBackward1]
	139954294144304 -> 139954294144160
	139954294144304 [label=AddmmBackward0]
	139954427650352 -> 139954294144304
	139954294144400 -> 139954294144304
	139954294144400 [label=LeakyReluBackward1]
	139954294144544 -> 139954294144400
	139954294144544 [label=AddmmBackward0]
	139954427653808 -> 139954294144544
	139954294144640 -> 139954294144544
	139954294144640 [label=SqueezeBackward1]
	139954294144784 -> 139954294144640
	139954294144784 [label=TransposeBackward0]
	139954294144880 -> 139954294144784
	139954294144880 [label=LeakyReluBackward1]
	139954294144976 -> 139954294144880
	139954294144976 [label=CudnnBatchNormBackward0]
	139954294144688 -> 139954294144976
	139954294144688 [label=ConvolutionBackward0]
	139954293727440 -> 139954294144688
	139954293727440 [label=TransposeBackward0]
	139954293727536 -> 139954293727440
	139954293727536 [label=SumBackward1]
	139954293727632 -> 139954293727536
	139954293727632 [label=MulBackward0]
	139954293727728 -> 139954293727632
	139954293727728 [label=IndexPutBackward0]
	139954293727872 -> 139954293727728
	139954293727872 [label=CatBackward0]
	139954293727968 -> 139954293727872
	139954293727968 [label=IndexBackward0]
	139954293728064 -> 139954293727968
	139954293728064 [label=CatBackward0]
	139954293728160 -> 139954293728064
	139954293728160 [label=IndexBackward0]
	139954293728256 -> 139954293728160
	139954293728256 [label=ReluBackward0]
	139954293728352 -> 139954293728256
	139954293728352 [label=AddmmBackward0]
	139954396719328 -> 139954293728352
	139954396719280 -> 139954293728352
	139954293728448 -> 139954293728352
	139954293728448 [label=TBackward0]
	139954396719760 -> 139954293728448
	139954293727680 -> 139954293727632
	139954293727680 [label=SoftmaxBackward0]
	139954293728016 -> 139954293727680
	139954293728016 [label=ViewBackward0]
	139954293728208 -> 139954293728016
	139954293728208 [label=AddmmBackward0]
	139954396719376 -> 139954293728208
	139954293728400 -> 139954293728208
	139954293728400 [label=ViewBackward0]
	139954293727728 -> 139954293728400
	139954293728304 -> 139954293728208
	139954293728304 [label=TBackward0]
	139954396719472 -> 139954293728304
	139954396717408 -> 139954294144688
	139954396718752 -> 139954294144976
	139954396717120 -> 139954294144976
	139954294144592 -> 139954294144544
	139954294144592 [label=TBackward0]
	139954427616272 -> 139954294144592
	139954294144352 -> 139954294144304
	139954294144352 [label=TBackward0]
	139954427614016 -> 139954294144352
	139954294144112 -> 139954294142336
	139954294144112 [label=TBackward0]
	139954427614208 -> 139954294144112
	139954294143152 -> 139954294141088
	139954294143152 [label=LeakyReluBackward1]
	139954294144928 -> 139954294143152
	139954294144928 [label=AddmmBackward0]
	139954427650304 -> 139954294144928
	139954294144640 -> 139954294144928
	139954294144256 -> 139954294144928
	139954294144256 [label=TBackward0]
	139954396717744 -> 139954294144256
	139954294142192 -> 139954294122336
	139954294142192 [label=TBackward0]
	139954427651984 -> 139954294142192
	139954294123536 -> 139954294122576
	139954294123536 [label=TBackward0]
	139954427652704 -> 139954294123536
	139954294100320 -> 139954294079840
	139954294100320 [label=TBackward0]
	139954427588128 -> 139954294100320
	139954294079936 -> 139954294079552
	139954294079936 [label=TBackward0]
	139954427588080 -> 139954294079936
	139954294038688 -> 139954396720336
	139954294038688 [label=DivBackward0]
	139954294065568 -> 139954294038688
	139954294065568 [label=SubBackward0]
	139954294082576 -> 139954294065568
	139954294082576 [label=SqueezeBackward1]
	139954294103056 -> 139954294082576
	139954294103056 [label=TanhBackward0]
	139954294123248 -> 139954294103056
	139954294123248 [label=AddmmBackward0]
	139954427584816 -> 139954294123248
	139954294121328 -> 139954294123248
	139954294121328 [label=AddmmBackward0]
	139954427586736 -> 139954294121328
	139954294144496 -> 139954294121328
	139954294144496 [label=CatBackward0]
	139954294144832 -> 139954294144496
	139954294144832 [label=LeakyReluBackward1]
	139954294144736 -> 139954294144832
	139954294144736 [label=AddmmBackward0]
	139954427574640 -> 139954294144736
	139954293727488 -> 139954294144736
	139954293727488 [label=LeakyReluBackward1]
	139954293727920 -> 139954293727488
	139954293727920 [label=AddmmBackward0]
	139954427652128 -> 139954293727920
	139954293727824 -> 139954293727920
	139954293727824 [label=AddBackward0]
	139954293727776 -> 139954293727824
	139954293727776 [label=LeakyReluBackward1]
	139954293728688 -> 139954293727776
	139954293728688 [label=AddmmBackward0]
	139954427652416 -> 139954293728688
	139954293728784 -> 139954293728688
	139954293728784 [label=LeakyReluBackward1]
	139954293728928 -> 139954293728784
	139954293728928 [label=AddmmBackward0]
	139954427650352 -> 139954293728928
	139954293729024 -> 139954293728928
	139954293729024 [label=LeakyReluBackward1]
	139954293729168 -> 139954293729024
	139954293729168 [label=AddmmBackward0]
	139954427653808 -> 139954293729168
	139954293729264 -> 139954293729168
	139954293729264 [label=SqueezeBackward1]
	139954293729408 -> 139954293729264
	139954293729408 [label=TransposeBackward0]
	139954293729504 -> 139954293729408
	139954293729504 [label=LeakyReluBackward1]
	139954293729600 -> 139954293729504
	139954293729600 [label=CudnnBatchNormBackward0]
	139954293729696 -> 139954293729600
	139954293729696 [label=ConvolutionBackward0]
	139954293729792 -> 139954293729696
	139954293729792 [label=TransposeBackward0]
	139954293729888 -> 139954293729792
	139954293729888 [label=SumBackward1]
	139954293729984 -> 139954293729888
	139954293729984 [label=MulBackward0]
	139954293730080 -> 139954293729984
	139954293730080 [label=IndexPutBackward0]
	139954293730224 -> 139954293730080
	139954293730224 [label=CatBackward0]
	139954293730320 -> 139954293730224
	139954293730320 [label=IndexBackward0]
	139954293730416 -> 139954293730320
	139954293730416 [label=CatBackward0]
	139954293730512 -> 139954293730416
	139954293730512 [label=IndexBackward0]
	139954293730608 -> 139954293730512
	139954293730608 [label=ReluBackward0]
	139954293730704 -> 139954293730608
	139954293730704 [label=AddmmBackward0]
	139954396719328 -> 139954293730704
	139954396719280 -> 139954293730704
	139954293730800 -> 139954293730704
	139954293730800 [label=TBackward0]
	139954396719760 -> 139954293730800
	139954293730032 -> 139954293729984
	139954293730032 [label=SoftmaxBackward0]
	139954293730368 -> 139954293730032
	139954293730368 [label=ViewBackward0]
	139954293730560 -> 139954293730368
	139954293730560 [label=AddmmBackward0]
	139954396719376 -> 139954293730560
	139954293730752 -> 139954293730560
	139954293730752 [label=ViewBackward0]
	139954293730080 -> 139954293730752
	139954293730656 -> 139954293730560
	139954293730656 [label=TBackward0]
	139954396719472 -> 139954293730656
	139954396717408 -> 139954293729696
	139954396718752 -> 139954293729600
	139954396717120 -> 139954293729600
	139954293729216 -> 139954293729168
	139954293729216 [label=TBackward0]
	139954427616272 -> 139954293729216
	139954293728976 -> 139954293728928
	139954293728976 [label=TBackward0]
	139954427614016 -> 139954293728976
	139954293728736 -> 139954293728688
	139954293728736 [label=TBackward0]
	139954427614208 -> 139954293728736
	139954293728496 -> 139954293727824
	139954293728496 [label=LeakyReluBackward1]
	139954293729552 -> 139954293728496
	139954293729552 [label=AddmmBackward0]
	139954427650304 -> 139954293729552
	139954293729264 -> 139954293729552
	139954293728880 -> 139954293729552
	139954293728880 [label=TBackward0]
	139954396717744 -> 139954293728880
	139954293728112 -> 139954293727920
	139954293728112 [label=TBackward0]
	139954427651984 -> 139954293728112
	139954293727392 -> 139954294144736
	139954293727392 [label=TBackward0]
	139954427652704 -> 139954293727392
	139954294143008 -> 139954294121328
	139954294143008 [label=TBackward0]
	139954427588128 -> 139954294143008
	139954294141040 -> 139954294123248
	139954294141040 [label=TBackward0]
	139954427588080 -> 139954294141040
	139954294064992 -> 139954294065568
	139954294064992 [label=SqueezeBackward1]
	139954294122192 -> 139954294064992
	139954294122192 [label=TanhBackward0]
	139954294144448 -> 139954294122192
	139954294144448 [label=AddmmBackward0]
	139954427584816 -> 139954294144448
	139954294144064 -> 139954294144448
	139954294144064 [label=AddmmBackward0]
	139954427586736 -> 139954294144064
	139954293727296 -> 139954294144064
	139954293727296 [label=CatBackward0]
	139954293729120 -> 139954293727296
	139954293729120 [label=LeakyReluBackward1]
	139954293728640 -> 139954293729120
	139954293728640 [label=AddmmBackward0]
	139954427574640 -> 139954293728640
	139954293729360 -> 139954293728640
	139954293729360 [label=LeakyReluBackward1]
	139954293729840 -> 139954293729360
	139954293729840 [label=AddmmBackward0]
	139954427652128 -> 139954293729840
	139954293729312 -> 139954293729840
	139954293729312 [label=AddBackward0]
	139954293730176 -> 139954293729312
	139954293730176 [label=LeakyReluBackward1]
	139954293730128 -> 139954293730176
	139954293730128 [label=AddmmBackward0]
	139954427652416 -> 139954293730128
	139954293730992 -> 139954293730128
	139954293730992 [label=LeakyReluBackward1]
	139954293731136 -> 139954293730992
	139954293731136 [label=AddmmBackward0]
	139954427650352 -> 139954293731136
	139954293731232 -> 139954293731136
	139954293731232 [label=LeakyReluBackward1]
	139954293731280 -> 139954293731232
	139954293731280 [label=AddmmBackward0]
	139954427653808 -> 139954293731280
	139954293752016 -> 139954293731280
	139954293752016 [label=SqueezeBackward1]
	139954293752160 -> 139954293752016
	139954293752160 [label=TransposeBackward0]
	139954293752256 -> 139954293752160
	139954293752256 [label=LeakyReluBackward1]
	139954293752352 -> 139954293752256
	139954293752352 [label=CudnnBatchNormBackward0]
	139954293752448 -> 139954293752352
	139954293752448 [label=ConvolutionBackward0]
	139954293752544 -> 139954293752448
	139954293752544 [label=TransposeBackward0]
	139954293752640 -> 139954293752544
	139954293752640 [label=SumBackward1]
	139954293752736 -> 139954293752640
	139954293752736 [label=MulBackward0]
	139954293752832 -> 139954293752736
	139954293752832 [label=IndexPutBackward0]
	139954293752976 -> 139954293752832
	139954293752976 [label=CatBackward0]
	139954293753072 -> 139954293752976
	139954293753072 [label=IndexBackward0]
	139954293753168 -> 139954293753072
	139954293753168 [label=CatBackward0]
	139954293753264 -> 139954293753168
	139954293753264 [label=IndexBackward0]
	139954293753360 -> 139954293753264
	139954293753360 [label=ReluBackward0]
	139954293753456 -> 139954293753360
	139954293753456 [label=AddmmBackward0]
	139954396719328 -> 139954293753456
	139954396719280 -> 139954293753456
	139954293753552 -> 139954293753456
	139954293753552 [label=TBackward0]
	139954396719760 -> 139954293753552
	139954293752784 -> 139954293752736
	139954293752784 [label=SoftmaxBackward0]
	139954293753120 -> 139954293752784
	139954293753120 [label=ViewBackward0]
	139954293753312 -> 139954293753120
	139954293753312 [label=AddmmBackward0]
	139954396719376 -> 139954293753312
	139954293753504 -> 139954293753312
	139954293753504 [label=ViewBackward0]
	139954293752832 -> 139954293753504
	139954293753408 -> 139954293753312
	139954293753408 [label=TBackward0]
	139954396719472 -> 139954293753408
	139954396717408 -> 139954293752448
	139954396718752 -> 139954293752352
	139954396717120 -> 139954293752352
	139954293751968 -> 139954293731280
	139954293751968 [label=TBackward0]
	139954427616272 -> 139954293751968
	139954293731184 -> 139954293731136
	139954293731184 [label=TBackward0]
	139954427614016 -> 139954293731184
	139954293730944 -> 139954293730128
	139954293730944 [label=TBackward0]
	139954427614208 -> 139954293730944
	139954293730464 -> 139954293729312
	139954293730464 [label=LeakyReluBackward1]
	139954293731040 -> 139954293730464
	139954293731040 [label=AddmmBackward0]
	139954427650304 -> 139954293731040
	139954293752016 -> 139954293731040
	139954293731088 -> 139954293731040
	139954293731088 [label=TBackward0]
	139954396717744 -> 139954293731088
	139954293729936 -> 139954293729840
	139954293729936 [label=TBackward0]
	139954427651984 -> 139954293729936
	139954293729456 -> 139954293728640
	139954293729456 [label=TBackward0]
	139954427652704 -> 139954293729456
	139954293727584 -> 139954294144064
	139954293727584 [label=TBackward0]
	139954427588128 -> 139954293727584
	139954294144208 -> 139954294144448
	139954294144208 [label=TBackward0]
	139954427588080 -> 139954294144208
	139954294040320 -> 139954396720336
	139954294040320 [label=DivBackward0]
	139954294121088 -> 139954294040320
	139954294121088 [label=SubBackward0]
	139954294144016 -> 139954294121088
	139954294144016 [label=SqueezeBackward1]
	139954293728832 -> 139954294144016
	139954293728832 [label=TanhBackward0]
	139954293730848 -> 139954293728832
	139954293730848 [label=AddmmBackward0]
	139954427584816 -> 139954293730848
	139954293729744 -> 139954293730848
	139954293729744 [label=AddmmBackward0]
	139954427586736 -> 139954293729744
	139954293730272 -> 139954293729744
	139954293730272 [label=CatBackward0]
	139954293752208 -> 139954293730272
	139954293752208 [label=LeakyReluBackward1]
	139954293752400 -> 139954293752208
	139954293752400 [label=AddmmBackward0]
	139954427574640 -> 139954293752400
	139954293752592 -> 139954293752400
	139954293752592 [label=LeakyReluBackward1]
	139954293753024 -> 139954293752592
	139954293753024 [label=AddmmBackward0]
	139954427652128 -> 139954293753024
	139954293752928 -> 139954293753024
	139954293752928 [label=AddBackward0]
	139954293752880 -> 139954293752928
	139954293752880 [label=LeakyReluBackward1]
	139954293753792 -> 139954293752880
	139954293753792 [label=AddmmBackward0]
	139954427652416 -> 139954293753792
	139954293753888 -> 139954293753792
	139954293753888 [label=LeakyReluBackward1]
	139954293754032 -> 139954293753888
	139954293754032 [label=AddmmBackward0]
	139954427650352 -> 139954293754032
	139954293754128 -> 139954293754032
	139954293754128 [label=LeakyReluBackward1]
	139954293754272 -> 139954293754128
	139954293754272 [label=AddmmBackward0]
	139954427653808 -> 139954293754272
	139954293754368 -> 139954293754272
	139954293754368 [label=SqueezeBackward1]
	139954293754512 -> 139954293754368
	139954293754512 [label=TransposeBackward0]
	139954293754608 -> 139954293754512
	139954293754608 [label=LeakyReluBackward1]
	139954293754704 -> 139954293754608
	139954293754704 [label=CudnnBatchNormBackward0]
	139954293754800 -> 139954293754704
	139954293754800 [label=ConvolutionBackward0]
	139954293754896 -> 139954293754800
	139954293754896 [label=TransposeBackward0]
	139954293754992 -> 139954293754896
	139954293754992 [label=SumBackward1]
	139954293755088 -> 139954293754992
	139954293755088 [label=MulBackward0]
	139954293755184 -> 139954293755088
	139954293755184 [label=IndexPutBackward0]
	139954293755328 -> 139954293755184
	139954293755328 [label=CatBackward0]
	139954293755424 -> 139954293755328
	139954293755424 [label=IndexBackward0]
	139954293755520 -> 139954293755424
	139954293755520 [label=CatBackward0]
	139954293755616 -> 139954293755520
	139954293755616 [label=IndexBackward0]
	139954293755712 -> 139954293755616
	139954293755712 [label=ReluBackward0]
	139954293755808 -> 139954293755712
	139954293755808 [label=AddmmBackward0]
	139954396719328 -> 139954293755808
	139954396719280 -> 139954293755808
	139954293755856 -> 139954293755808
	139954293755856 [label=TBackward0]
	139954396719760 -> 139954293755856
	139954293755136 -> 139954293755088
	139954293755136 [label=SoftmaxBackward0]
	139954293755472 -> 139954293755136
	139954293755472 [label=ViewBackward0]
	139954293755664 -> 139954293755472
	139954293755664 [label=AddmmBackward0]
	139954396719376 -> 139954293755664
	139954293755232 -> 139954293755664
	139954293755232 [label=ViewBackward0]
	139954293755184 -> 139954293755232
	139954293755760 -> 139954293755664
	139954293755760 [label=TBackward0]
	139954396719472 -> 139954293755760
	139954396717408 -> 139954293754800
	139954396718752 -> 139954293754704
	139954396717120 -> 139954293754704
	139954293754320 -> 139954293754272
	139954293754320 [label=TBackward0]
	139954427616272 -> 139954293754320
	139954293754080 -> 139954293754032
	139954293754080 [label=TBackward0]
	139954427614016 -> 139954293754080
	139954293753840 -> 139954293753792
	139954293753840 [label=TBackward0]
	139954427614208 -> 139954293753840
	139954293753600 -> 139954293752928
	139954293753600 [label=LeakyReluBackward1]
	139954293754656 -> 139954293753600
	139954293754656 [label=AddmmBackward0]
	139954427650304 -> 139954293754656
	139954293754368 -> 139954293754656
	139954293753984 -> 139954293754656
	139954293753984 [label=TBackward0]
	139954396717744 -> 139954293753984
	139954293753216 -> 139954293753024
	139954293753216 [label=TBackward0]
	139954427651984 -> 139954293753216
	139954293752496 -> 139954293752400
	139954293752496 [label=TBackward0]
	139954427652704 -> 139954293752496
	139954293730896 -> 139954293729744
	139954293730896 [label=TBackward0]
	139954427588128 -> 139954293730896
	139954293729648 -> 139954293730848
	139954293729648 [label=TBackward0]
	139954427588080 -> 139954293729648
	139954294063552 -> 139954294121088
	139954294063552 [label=SqueezeBackward1]
	139954293729072 -> 139954294063552
	139954293729072 [label=TanhBackward0]
	139954293728592 -> 139954293729072
	139954293728592 [label=AddmmBackward0]
	139954427584816 -> 139954293728592
	139954293752304 -> 139954293728592
	139954293752304 [label=AddmmBackward0]
	139954427586736 -> 139954293752304
	139954293752064 -> 139954293752304
	139954293752064 [label=CatBackward0]
	139954293754224 -> 139954293752064
	139954293754224 [label=LeakyReluBackward1]
	139954293753744 -> 139954293754224
	139954293753744 [label=AddmmBackward0]
	139954427574640 -> 139954293753744
	139954293754464 -> 139954293753744
	139954293754464 [label=LeakyReluBackward1]
	139954293754944 -> 139954293754464
	139954293754944 [label=AddmmBackward0]
	139954427652128 -> 139954293754944
	139954293754416 -> 139954293754944
	139954293754416 [label=AddBackward0]
	139954293755280 -> 139954293754416
	139954293755280 [label=LeakyReluBackward1]
	139954293780640 -> 139954293755280
	139954293780640 [label=AddmmBackward0]
	139954427652416 -> 139954293780640
	139954293780736 -> 139954293780640
	139954293780736 [label=LeakyReluBackward1]
	139954293780880 -> 139954293780736
	139954293780880 [label=AddmmBackward0]
	139954427650352 -> 139954293780880
	139954293780976 -> 139954293780880
	139954293780976 [label=LeakyReluBackward1]
	139954293781120 -> 139954293780976
	139954293781120 [label=AddmmBackward0]
	139954427653808 -> 139954293781120
	139954293781216 -> 139954293781120
	139954293781216 [label=SqueezeBackward1]
	139954293781360 -> 139954293781216
	139954293781360 [label=TransposeBackward0]
	139954293781456 -> 139954293781360
	139954293781456 [label=LeakyReluBackward1]
	139954293781552 -> 139954293781456
	139954293781552 [label=CudnnBatchNormBackward0]
	139954293781648 -> 139954293781552
	139954293781648 [label=ConvolutionBackward0]
	139954293781744 -> 139954293781648
	139954293781744 [label=TransposeBackward0]
	139954293781840 -> 139954293781744
	139954293781840 [label=SumBackward1]
	139954293781936 -> 139954293781840
	139954293781936 [label=MulBackward0]
	139954293782032 -> 139954293781936
	139954293782032 [label=IndexPutBackward0]
	139954293782176 -> 139954293782032
	139954293782176 [label=CatBackward0]
	139954293782272 -> 139954293782176
	139954293782272 [label=IndexBackward0]
	139954293782368 -> 139954293782272
	139954293782368 [label=CatBackward0]
	139954293782464 -> 139954293782368
	139954293782464 [label=IndexBackward0]
	139954293782560 -> 139954293782464
	139954293782560 [label=ReluBackward0]
	139954293782656 -> 139954293782560
	139954293782656 [label=AddmmBackward0]
	139954396719328 -> 139954293782656
	139954396719280 -> 139954293782656
	139954293782752 -> 139954293782656
	139954293782752 [label=TBackward0]
	139954396719760 -> 139954293782752
	139954293781984 -> 139954293781936
	139954293781984 [label=SoftmaxBackward0]
	139954293782320 -> 139954293781984
	139954293782320 [label=ViewBackward0]
	139954293782512 -> 139954293782320
	139954293782512 [label=AddmmBackward0]
	139954396719376 -> 139954293782512
	139954293782704 -> 139954293782512
	139954293782704 [label=ViewBackward0]
	139954293782032 -> 139954293782704
	139954293782608 -> 139954293782512
	139954293782608 [label=TBackward0]
	139954396719472 -> 139954293782608
	139954396717408 -> 139954293781648
	139954396718752 -> 139954293781552
	139954396717120 -> 139954293781552
	139954293781168 -> 139954293781120
	139954293781168 [label=TBackward0]
	139954427616272 -> 139954293781168
	139954293780928 -> 139954293780880
	139954293780928 [label=TBackward0]
	139954427614016 -> 139954293780928
	139954293780688 -> 139954293780640
	139954293780688 [label=TBackward0]
	139954427614208 -> 139954293780688
	139954293755568 -> 139954293754416
	139954293755568 [label=LeakyReluBackward1]
	139954293781504 -> 139954293755568
	139954293781504 [label=AddmmBackward0]
	139954427650304 -> 139954293781504
	139954293781216 -> 139954293781504
	139954293780832 -> 139954293781504
	139954293780832 [label=TBackward0]
	139954396717744 -> 139954293780832
	139954293755040 -> 139954293754944
	139954293755040 [label=TBackward0]
	139954427651984 -> 139954293755040
	139954293754560 -> 139954293753744
	139954293754560 [label=TBackward0]
	139954427652704 -> 139954293754560
	139954293752688 -> 139954293752304
	139954293752688 [label=TBackward0]
	139954427588128 -> 139954293752688
	139954293751920 -> 139954293728592
	139954293751920 [label=TBackward0]
	139954427588080 -> 139954293751920
	139954427585536 -> 139954398104784
	139954427585536 [label=MulBackward0]
	139954427585920 -> 139954427585536
	139954427585920 [label=L1LossBackward0]
	139954427651648 -> 139954427585920
	139954427651648 [label=ClampBackward1]
	139954396720624 -> 139954427651648
	139954396720624 [label=SqueezeBackward1]
	139954294100080 -> 139954396720624
	139954294100080 [label=LeakyReluBackward1]
	139954293728544 -> 139954294100080
	139954293728544 [label=AddmmBackward0]
	139954396719712 -> 139954293728544
	139954425402768 [label="mask_decoder.out.1.bias
 (1)" fillcolor=lightblue]
	139954425402768 -> 139954396719712
	139954396719712 [label=AccumulateGrad]
	139954293752112 -> 139954293728544
	139954293752112 [label=AddmmBackward0]
	139954293753696 -> 139954293752112
	139954425402608 [label="mask_decoder.out.0.bias
 (32)" fillcolor=lightblue]
	139954425402608 -> 139954293753696
	139954293753696 [label=AccumulateGrad]
	139954293753936 -> 139954293752112
	139954293753936 [label=CatBackward0]
	139954293754752 -> 139954293753936
	139954293754752 [label=LeakyReluBackward1]
	139954293781072 -> 139954293754752
	139954293781072 [label=AddmmBackward0]
	139954293780592 -> 139954293781072
	139954425402448 [label="mask_decoder.per_scale_out.0.after_skip.1.0.bias
 (32)" fillcolor=lightblue]
	139954425402448 -> 139954293780592
	139954293780592 [label=AccumulateGrad]
	139954293781024 -> 139954293781072
	139954293781024 [label=LeakyReluBackward1]
	139954293781312 -> 139954293781024
	139954293781312 [label=AddmmBackward0]
	139954293781888 -> 139954293781312
	139954425402288 [label="mask_decoder.per_scale_out.0.after_skip.0.0.bias
 (32)" fillcolor=lightblue]
	139954425402288 -> 139954293781888
	139954293781888 [label=AccumulateGrad]
	139954293781792 -> 139954293781312
	139954293781792 [label=AddBackward0]
	139954293782224 -> 139954293781792
	139954293782224 [label=LeakyReluBackward1]
	139954293782080 -> 139954293782224
	139954293782080 [label=AddmmBackward0]
	139954293782944 -> 139954293782080
	139954425402128 [label="mask_decoder.per_scale_out.0.before_skip.1.0.bias
 (32)" fillcolor=lightblue]
	139954425402128 -> 139954293782944
	139954293782944 [label=AccumulateGrad]
	139954293782896 -> 139954293782080
	139954293782896 [label=LeakyReluBackward1]
	139954293783040 -> 139954293782896
	139954293783040 [label=AddmmBackward0]
	139954293783232 -> 139954293783040
	139954425401968 [label="mask_decoder.per_scale_out.0.before_skip.0.0.bias
 (32)" fillcolor=lightblue]
	139954425401968 -> 139954293783232
	139954293783232 [label=AccumulateGrad]
	139954293783184 -> 139954293783040
	139954293783184 [label=LeakyReluBackward1]
	139954293783328 -> 139954293783184
	139954293783328 [label=AddmmBackward0]
	139954293783520 -> 139954293783328
	139954425401648 [label="mask_decoder.per_scale_out.0.in_layer.0.bias
 (32)" fillcolor=lightblue]
	139954425401648 -> 139954293783520
	139954293783520 [label=AccumulateGrad]
	139954293783472 -> 139954293783328
	139954293783472 [label=SqueezeBackward1]
	139954293783616 -> 139954293783472
	139954293783616 [label=TransposeBackward0]
	139954293783808 -> 139954293783616
	139954293783808 [label=LeakyReluBackward1]
	139954293783904 -> 139954293783808
	139954293783904 [label=CudnnBatchNormBackward0]
	139954293784000 -> 139954293783904
	139954293784000 [label=ConvolutionBackward0]
	139954293784192 -> 139954293784000
	139954293784192 [label=TransposeBackward0]
	139954293784336 -> 139954293784192
	139954293784336 [label=SumBackward1]
	139954293784432 -> 139954293784336
	139954293784432 [label=MulBackward0]
	139954293784528 -> 139954293784432
	139954293784528 [label=IndexPutBackward0]
	139954293805216 -> 139954293784528
	139954293805216 [label=CatBackward0]
	139954293805312 -> 139954293805216
	139954293805312 [label=IndexBackward0]
	139954293805408 -> 139954293805312
	139954293805408 [label=CatBackward0]
	139954293805504 -> 139954293805408
	139954293805504 [label=IndexBackward0]
	139954293805600 -> 139954293805504
	139954293805600 [label=ReluBackward0]
	139954293805696 -> 139954293805600
	139954293805696 [label=AddmmBackward0]
	139954293805792 -> 139954293805696
	139954425810272 [label="mask_decoder.per_scale_in.0.0.bias
 (8)" fillcolor=lightblue]
	139954425810272 -> 139954293805792
	139954293805792 [label=AccumulateGrad]
	139954396719280 -> 139954293805696
	139954293805744 -> 139954293805696
	139954293805744 [label=TBackward0]
	139954293805840 -> 139954293805744
	139954425810192 [label="mask_decoder.per_scale_in.0.0.weight
 (8, 8)" fillcolor=lightblue]
	139954425810192 -> 139954293805840
	139954293805840 [label=AccumulateGrad]
	139954293784480 -> 139954293784432
	139954293784480 [label=SoftmaxBackward0]
	139954293805360 -> 139954293784480
	139954293805360 [label=ViewBackward0]
	139954293805552 -> 139954293805360
	139954293805552 [label=AddmmBackward0]
	139954293805120 -> 139954293805552
	139954425810432 [label="mask_decoder.per_scale_att_pooling.0.fc.bias
 (71)" fillcolor=lightblue]
	139954425810432 -> 139954293805120
	139954293805120 [label=AccumulateGrad]
	139954293805648 -> 139954293805552
	139954293805648 [label=ViewBackward0]
	139954293784528 -> 139954293805648
	139954293805168 -> 139954293805552
	139954293805168 [label=TBackward0]
	139954293805936 -> 139954293805168
	139954425810352 [label="mask_decoder.per_scale_att_pooling.0.fc.weight
 (71, 71)" fillcolor=lightblue]
	139954425810352 -> 139954293805936
	139954293805936 [label=AccumulateGrad]
	139954293784144 -> 139954293784000
	139954425810512 [label="mask_decoder.per_scale_att_pooling.0.mlp.conv.weight
 (71, 71, 1)" fillcolor=lightblue]
	139954425810512 -> 139954293784144
	139954293784144 [label=AccumulateGrad]
	139954293783952 -> 139954293783904
	139954425810672 [label="mask_decoder.per_scale_att_pooling.0.mlp.bn.bn.weight
 (71)" fillcolor=lightblue]
	139954425810672 -> 139954293783952
	139954293783952 [label=AccumulateGrad]
	139954293783712 -> 139954293783904
	139954425810752 [label="mask_decoder.per_scale_att_pooling.0.mlp.bn.bn.bias
 (71)" fillcolor=lightblue]
	139954425810752 -> 139954293783712
	139954293783712 [label=AccumulateGrad]
	139954293783424 -> 139954293783328
	139954293783424 [label=TBackward0]
	139954293783856 -> 139954293783424
	139954425401568 [label="mask_decoder.per_scale_out.0.in_layer.0.weight
 (32, 71)" fillcolor=lightblue]
	139954425401568 -> 139954293783856
	139954293783856 [label=AccumulateGrad]
	139954293783136 -> 139954293783040
	139954293783136 [label=TBackward0]
	139954293783760 -> 139954293783136
	139954425401888 [label="mask_decoder.per_scale_out.0.before_skip.0.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425401888 -> 139954293783760
	139954293783760 [label=AccumulateGrad]
	139954293782848 -> 139954293782080
	139954293782848 [label=TBackward0]
	139954293783568 -> 139954293782848
	139954425402048 [label="mask_decoder.per_scale_out.0.before_skip.1.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425402048 -> 139954293783568
	139954293783568 [label=AccumulateGrad]
	139954293782416 -> 139954293781792
	139954293782416 [label=LeakyReluBackward1]
	139954293783280 -> 139954293782416
	139954293783280 [label=AddmmBackward0]
	139954293784048 -> 139954293783280
	139954425401808 [label="mask_decoder.per_scale_out.0.skip_proj.0.bias
 (32)" fillcolor=lightblue]
	139954425401808 -> 139954293784048
	139954293784048 [label=AccumulateGrad]
	139954293783472 -> 139954293783280
	139954293784096 -> 139954293783280
	139954293784096 [label=TBackward0]
	139954293783088 -> 139954293784096
	139954425401728 [label="mask_decoder.per_scale_out.0.skip_proj.0.weight
 (32, 71)" fillcolor=lightblue]
	139954425401728 -> 139954293783088
	139954293783088 [label=AccumulateGrad]
	139954293781696 -> 139954293781312
	139954293781696 [label=TBackward0]
	139954293782800 -> 139954293781696
	139954425402208 [label="mask_decoder.per_scale_out.0.after_skip.0.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425402208 -> 139954293782800
	139954293782800 [label=AccumulateGrad]
	139954293780784 -> 139954293781072
	139954293780784 [label=TBackward0]
	139954293782992 -> 139954293780784
	139954425402368 [label="mask_decoder.per_scale_out.0.after_skip.1.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425402368 -> 139954293782992
	139954293782992 [label=AccumulateGrad]
	139954293753648 -> 139954293752112
	139954293753648 [label=TBackward0]
	139954293754848 -> 139954293753648
	139954425402528 [label="mask_decoder.out.0.weight
 (32, 32)" fillcolor=lightblue]
	139954425402528 -> 139954293754848
	139954293754848 [label=AccumulateGrad]
	139954293751872 -> 139954293728544
	139954293751872 [label=TBackward0]
	139954293755376 -> 139954293751872
	139954425402688 [label="mask_decoder.out.1.weight
 (1, 32)" fillcolor=lightblue]
	139954425402688 -> 139954293755376
	139954293755376 [label=AccumulateGrad]
	139954398104784 -> 139954293956256
}
